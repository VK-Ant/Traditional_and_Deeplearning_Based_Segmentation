{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaccf256",
   "metadata": {
    "papermill": {
     "duration": 0.045109,
     "end_time": "2024-05-05T12:49:20.803731",
     "exception": false,
     "start_time": "2024-05-05T12:49:20.758622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Super Fast and Accurate 3D Object Detection\n",
    "Predicting Cars in Lidar data using SFA3D\n",
    "\n",
    "Github Link to Original Code: https://github.com/maudzung/SFA3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8d74f",
   "metadata": {
    "papermill": {
     "duration": 0.043694,
     "end_time": "2024-05-05T12:49:20.891180",
     "exception": false,
     "start_time": "2024-05-05T12:49:20.847486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b3aad",
   "metadata": {
    "papermill": {
     "duration": 0.042892,
     "end_time": "2024-05-05T12:49:20.978168",
     "exception": false,
     "start_time": "2024-05-05T12:49:20.935276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## KITT Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de61bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:21.083616Z",
     "iopub.status.busy": "2024-05-05T12:49:21.082539Z",
     "iopub.status.idle": "2024-05-05T12:49:21.103908Z",
     "shell.execute_reply": "2024-05-05T12:49:21.104473Z",
     "shell.execute_reply.started": "2021-12-13T06:44:51.658245Z"
    },
    "papermill": {
     "duration": 0.085459,
     "end_time": "2024-05-05T12:49:21.104769",
     "exception": false,
     "start_time": "2024-05-05T12:49:21.019310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Car and Van ==> Car class\n",
    "# Pedestrian and Person_Sitting ==> Pedestrian Class\n",
    "CLASS_NAME_TO_ID = {\n",
    "    'Pedestrian': 0,\n",
    "    'Car': 1,\n",
    "    'Cyclist': 2,\n",
    "    'Van': 1,\n",
    "    'Truck': -3,\n",
    "    'Person_sitting': 0,\n",
    "    'Tram': -99,\n",
    "    'Misc': -99,\n",
    "    'DontCare': -1\n",
    "}\n",
    "\n",
    "colors = [[0, 255, 255], [0, 0, 255], [255, 0, 0], [255, 120, 0],\n",
    "          [255, 120, 120], [0, 120, 0], [120, 255, 255], [120, 0, 255]]\n",
    "\n",
    "#####################################################################################\n",
    "boundary = {\n",
    "    \"minX\": 0,\n",
    "    \"maxX\": 50,\n",
    "    \"minY\": -25,\n",
    "    \"maxY\": 25,\n",
    "    \"minZ\": -2.73,\n",
    "    \"maxZ\": 1.27\n",
    "}\n",
    "\n",
    "bound_size_x = boundary['maxX'] - boundary['minX']\n",
    "bound_size_y = boundary['maxY'] - boundary['minY']\n",
    "bound_size_z = boundary['maxZ'] - boundary['minZ']\n",
    "\n",
    "boundary_back = {\n",
    "    \"minX\": -50,\n",
    "    \"maxX\": 0,\n",
    "    \"minY\": -25,\n",
    "    \"maxY\": 25,\n",
    "    \"minZ\": -2.73,\n",
    "    \"maxZ\": 1.27\n",
    "}\n",
    "\n",
    "BEV_WIDTH = 608  # across y axis -25m ~ 25m\n",
    "BEV_HEIGHT = 608  # across x axis 0m ~ 50m\n",
    "DISCRETIZATION = (boundary[\"maxX\"] - boundary[\"minX\"]) / BEV_HEIGHT\n",
    "\n",
    "# maximum number of points per voxel\n",
    "T = 35\n",
    "\n",
    "# voxel size\n",
    "vd = 0.1  # z\n",
    "vh = 0.05  # y\n",
    "vw = 0.05  # x\n",
    "\n",
    "# voxel grid\n",
    "W = math.ceil(bound_size_x / vw)\n",
    "H = math.ceil(bound_size_y / vh)\n",
    "D = math.ceil(bound_size_z / vd)\n",
    "\n",
    "# Following parameters are calculated as an average from KITTI dataset for simplicity\n",
    "#####################################################################################\n",
    "Tr_velo_to_cam = np.array([\n",
    "    [7.49916597e-03, -9.99971248e-01, -8.65110297e-04, -6.71807577e-03],\n",
    "    [1.18652889e-02, 9.54520517e-04, -9.99910318e-01, -7.33152811e-02],\n",
    "    [9.99882833e-01, 7.49141178e-03, 1.18719929e-02, -2.78557062e-01],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "# cal mean from train set\n",
    "R0 = np.array([\n",
    "    [0.99992475, 0.00975976, -0.00734152, 0],\n",
    "    [-0.0097913, 0.99994262, -0.00430371, 0],\n",
    "    [0.00729911, 0.0043753, 0.99996319, 0],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "P2 = np.array([[719.787081, 0., 608.463003, 44.9538775],\n",
    "               [0., 719.787081, 174.545111, 0.1066855],\n",
    "               [0., 0., 1., 3.0106472e-03],\n",
    "               [0., 0., 0., 0]\n",
    "               ])\n",
    "\n",
    "R0_inv = np.linalg.inv(R0)\n",
    "Tr_velo_to_cam_inv = np.linalg.inv(Tr_velo_to_cam)\n",
    "P2_inv = np.linalg.pinv(P2)\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b70e55f",
   "metadata": {
    "papermill": {
     "duration": 0.054534,
     "end_time": "2024-05-05T12:49:21.252433",
     "exception": false,
     "start_time": "2024-05-05T12:49:21.197899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb552db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:21.354600Z",
     "iopub.status.busy": "2024-05-05T12:49:21.353688Z",
     "iopub.status.idle": "2024-05-05T12:49:22.872956Z",
     "shell.execute_reply": "2024-05-05T12:49:22.872393Z",
     "shell.execute_reply.started": "2021-12-13T06:44:51.680494Z"
    },
    "papermill": {
     "duration": 1.579179,
     "end_time": "2024-05-05T12:49:22.873108",
     "exception": false,
     "start_time": "2024-05-05T12:49:21.293929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "def parse_configs():\n",
    "    config_dict = {}\n",
    "    config_dict['seed'] = 2020\n",
    "    config_dict['saved_fn'] = 'fpn_resnet_18'\n",
    "    config_dict['root_dir'] = './'\n",
    "    \n",
    "    ####################################################################\n",
    "    ##############     Model configs            ########################\n",
    "    ####################################################################\n",
    "    config_dict['arch'] = 'fpn_resnet_18'\n",
    "    config_dict['pretrained_path'] = None\n",
    "    ####################################################################\n",
    "    ##############     Dataloader and Running configs            #######\n",
    "    ####################################################################\n",
    "    config_dict['hflip_prob'] = 0.5\n",
    "    config_dict['no_val'] = False\n",
    "    config_dict['num_samples'] = None\n",
    "    config_dict['num_workers'] = 4\n",
    "    config_dict['batch_size'] = 16\n",
    "    config_dict['print_freq'] = 50\n",
    "    config_dict['tensorboard_freq'] = 50\n",
    "    config_dict['checkpoint_freq'] = 2\n",
    "    ####################################################################\n",
    "    ##############     Training strategy            ####################\n",
    "    ####################################################################\n",
    "    config_dict['start_epoch'] = 1\n",
    "    config_dict['num_epochs'] = 300\n",
    "    config_dict['lr_type'] = 'cosin'\n",
    "    config_dict['lr'] = 0.001\n",
    "    config_dict['minimum_lr'] = 1e-7\n",
    "    config_dict['momentum'] = 0.949\n",
    "    config_dict['weight_decay'] = 0\n",
    "    config_dict['optimizer_type'] = 'adam'\n",
    "    config_dict['steps'] = [150, 180]\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Loss weight            ##########################\n",
    "    ####################################################################\n",
    "\n",
    "    ####################################################################\n",
    "    ##############     Distributed Data Parallel            ############\n",
    "    ####################################################################\n",
    "    config_dict['world_size'] = -1\n",
    "    config_dict['rank'] = -1\n",
    "    config_dict['dist_url'] = 'tcp://127.0.0.1:29500'\n",
    "    config_dict['gpu_idx'] = 0\n",
    "    config_dict['no_cuda'] = False\n",
    "    config_dict['multiprocessing_distributed'] = False\n",
    "    ####################################################################\n",
    "    ##############     Evaluation configurations     ###################\n",
    "    ####################################################################\n",
    "    config_dict['evaluate'] = False\n",
    "    config_dict['resume_path'] = None\n",
    "    config_dict['K'] = 50\n",
    "\n",
    "    configs = edict(config_dict)\n",
    "\n",
    "    ####################################################################\n",
    "    ############## Hardware configurations #############################\n",
    "    ####################################################################\n",
    "    configs.device = torch.device('cpu' if configs.no_cuda else 'cuda')\n",
    "    configs.ngpus_per_node = torch.cuda.device_count()\n",
    "\n",
    "    configs.pin_memory = True\n",
    "    configs.input_size = (608, 608)\n",
    "    configs.hm_size = (152, 152)\n",
    "    configs.down_ratio = 4\n",
    "    configs.max_objects = 50\n",
    "\n",
    "    configs.imagenet_pretrained = True\n",
    "    configs.head_conv = 64\n",
    "    configs.num_classes = 3\n",
    "    configs.num_center_offset = 2\n",
    "    configs.num_z = 1\n",
    "    configs.num_dim = 3\n",
    "    configs.num_direction = 2  # sin, cos\n",
    "\n",
    "    configs.heads = {\n",
    "        'hm_cen': configs.num_classes,\n",
    "        'cen_offset': configs.num_center_offset,\n",
    "        'direction': configs.num_direction,\n",
    "        'z_coor': configs.num_z,\n",
    "        'dim': configs.num_dim\n",
    "    }\n",
    "\n",
    "    configs.num_input_features = 4\n",
    "\n",
    "    ####################################################################\n",
    "    ############## Dataset, logs, Checkpoints dir ######################\n",
    "    ####################################################################\n",
    "    configs.dataset_dir = '../input/kitti-3d-object-detection-dataset/'\n",
    "    configs.checkpoints_dir = os.path.join(configs.root_dir, 'checkpoints', configs.saved_fn)\n",
    "    configs.logs_dir = os.path.join(configs.root_dir, 'logs', configs.saved_fn)\n",
    "\n",
    "    if not os.path.isdir(configs.checkpoints_dir):\n",
    "        os.makedirs(configs.checkpoints_dir)\n",
    "    if not os.path.isdir(configs.logs_dir):\n",
    "        os.makedirs(configs.logs_dir)\n",
    "\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841477a",
   "metadata": {
    "papermill": {
     "duration": 0.039992,
     "end_time": "2024-05-05T12:49:22.954109",
     "exception": false,
     "start_time": "2024-05-05T12:49:22.914117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2500da",
   "metadata": {
    "papermill": {
     "duration": 0.042353,
     "end_time": "2024-05-05T12:49:23.037198",
     "exception": false,
     "start_time": "2024-05-05T12:49:22.994845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a82294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:23.174272Z",
     "iopub.status.busy": "2024-05-05T12:49:23.134019Z",
     "iopub.status.idle": "2024-05-05T12:49:23.232097Z",
     "shell.execute_reply": "2024-05-05T12:49:23.231525Z",
     "shell.execute_reply.started": "2021-12-13T06:44:51.779321Z"
    },
    "papermill": {
     "duration": 0.15285,
     "end_time": "2024-05-05T12:49:23.232235",
     "exception": false,
     "start_time": "2024-05-05T12:49:23.079385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def angle_in_limit(angle):\n",
    "    # To limit the angle in -pi/2 - pi/2\n",
    "    limit_degree = 5\n",
    "    while angle >= np.pi / 2:\n",
    "        angle -= np.pi\n",
    "    while angle < -np.pi / 2:\n",
    "        angle += np.pi\n",
    "    if abs(angle + np.pi / 2) < limit_degree / 180 * np.pi:\n",
    "        angle = np.pi / 2\n",
    "    return angle\n",
    "\n",
    "\n",
    "def camera_to_lidar(x, y, z, V2C=None, R0=None, P2=None):\n",
    "    p = np.array([x, y, z, 1])\n",
    "    if V2C is None or R0 is None:\n",
    "        p = np.matmul(R0_inv, p)\n",
    "        p = np.matmul(Tr_velo_to_cam_inv, p)\n",
    "    else:\n",
    "        R0_i = np.zeros((4, 4))\n",
    "        R0_i[:3, :3] = R0\n",
    "        R0_i[3, 3] = 1\n",
    "        p = np.matmul(np.linalg.inv(R0_i), p)\n",
    "        p = np.matmul(inverse_rigid_trans(V2C), p)\n",
    "    p = p[0:3]\n",
    "    return tuple(p)\n",
    "\n",
    "\n",
    "def lidar_to_camera(x, y, z, V2C=None, R0=None, P2=None):\n",
    "    p = np.array([x, y, z, 1])\n",
    "    if V2C is None or R0 is None:\n",
    "        p = np.matmul(Tr_velo_to_cam, p)\n",
    "        p = np.matmul(R0, p)\n",
    "    else:\n",
    "        p = np.matmul(V2C, p)\n",
    "        p = np.matmul(R0, p)\n",
    "    p = p[0:3]\n",
    "    return tuple(p)\n",
    "\n",
    "\n",
    "def camera_to_lidar_point(points):\n",
    "    # (N, 3) -> (N, 3)\n",
    "    N = points.shape[0]\n",
    "    points = np.hstack([points, np.ones((N, 1))]).T  # (N,4) -> (4,N)\n",
    "\n",
    "    points = np.matmul(R0_inv, points)\n",
    "    points = np.matmul(Tr_velo_to_cam_inv, points).T  # (4, N) -> (N, 4)\n",
    "    points = points[:, 0:3]\n",
    "    return points.reshape(-1, 3)\n",
    "\n",
    "\n",
    "def lidar_to_camera_point(points, V2C = None):\n",
    "    # (N, 3) -> (N, 3)\n",
    "    N = points.shape[0]\n",
    "    points = np.hstack([points, np.ones((N, 1))]).T\n",
    "\n",
    "    if V2C is None or R0 is None:\n",
    "        points = np.matmul(Tr_velo_to_cam, points)\n",
    "        points = np.matmul(R0, points).T\n",
    "    else:\n",
    "        points = np.matmul(V2C, points)\n",
    "        points = np.matmul(R0, points).T\n",
    "    points = points[:, 0:3]\n",
    "    return points.reshape(-1, 3)\n",
    "\n",
    "\n",
    "def camera_to_lidar_box(boxes, V2C=None, R0=None, P2=None):\n",
    "    # (N, 7) -> (N, 7) x,y,z,h,w,l,r\n",
    "    ret = []\n",
    "    for box in boxes:\n",
    "        x, y, z, h, w, l, ry = box\n",
    "        (x, y, z), h, w, l, rz = camera_to_lidar(x, y, z, V2C=V2C, R0=R0, P2=P2), h, w, l, -ry - np.pi / 2\n",
    "        # rz = angle_in_limit(rz)\n",
    "        ret.append([x, y, z, h, w, l, rz])\n",
    "    return np.array(ret).reshape(-1, 7)\n",
    "\n",
    "\n",
    "def lidar_to_camera_box(boxes, V2C=None, R0=None, P2=None):\n",
    "    # (N, 7) -> (N, 7) x,y,z,h,w,l,r\n",
    "    ret = []\n",
    "    for box in boxes:\n",
    "        x, y, z, h, w, l, rz = box\n",
    "        (x, y, z), h, w, l, ry = lidar_to_camera(x, y, z, V2C=V2C, R0=R0, P2=P2), h, w, l, -rz - np.pi / 2\n",
    "        # ry = angle_in_limit(ry)\n",
    "        ret.append([x, y, z, h, w, l, ry])\n",
    "    return np.array(ret).reshape(-1, 7)\n",
    "\n",
    "\n",
    "def center_to_corner_box2d(boxes_center, coordinate='lidar'):\n",
    "    # (N, 5) -> (N, 4, 2)\n",
    "    N = boxes_center.shape[0]\n",
    "    boxes3d_center = np.zeros((N, 7))\n",
    "    boxes3d_center[:, [0, 1, 4, 5, 6]] = boxes_center\n",
    "    boxes3d_corner = center_to_corner_box3d(boxes3d_center, coordinate=coordinate)\n",
    "\n",
    "    return boxes3d_corner[:, 0:4, 0:2]\n",
    "\n",
    "\n",
    "def center_to_corner_box3d(boxes_center, coordinate='lidar'):\n",
    "    # (N, 7) -> (N, 8, 3)\n",
    "    N = boxes_center.shape[0]\n",
    "    ret = np.zeros((N, 8, 3), dtype=np.float32)\n",
    "\n",
    "    if coordinate == 'camera':\n",
    "        boxes_center = camera_to_lidar_box(boxes_center)\n",
    "\n",
    "    for i in range(N):\n",
    "        box = boxes_center[i]\n",
    "        translation = box[0:3]\n",
    "        size = box[3:6]\n",
    "        rotation = [0, 0, box[-1]]\n",
    "\n",
    "        h, w, l = size[0], size[1], size[2]\n",
    "        trackletBox = np.array([  # in velodyne coordinates around zero point and without orientation yet\n",
    "            [-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2], \\\n",
    "            [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2], \\\n",
    "            [0, 0, 0, 0, h, h, h, h]])\n",
    "\n",
    "        # re-create 3D bounding box in velodyne coordinate system\n",
    "        yaw = rotation[2]\n",
    "        rotMat = np.array([\n",
    "            [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "            [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "            [0.0, 0.0, 1.0]])\n",
    "        cornerPosInVelo = np.dot(rotMat, trackletBox) + np.tile(translation, (8, 1)).T\n",
    "        box3d = cornerPosInVelo.transpose()\n",
    "        ret[i] = box3d\n",
    "\n",
    "    if coordinate == 'camera':\n",
    "        for idx in range(len(ret)):\n",
    "            ret[idx] = lidar_to_camera_point(ret[idx])\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "CORNER2CENTER_AVG = True\n",
    "\n",
    "\n",
    "def corner_to_center_box3d(boxes_corner, coordinate='camera'):\n",
    "    # (N, 8, 3) -> (N, 7) x,y,z,h,w,l,ry/z\n",
    "    if coordinate == 'lidar':\n",
    "        for idx in range(len(boxes_corner)):\n",
    "            boxes_corner[idx] = lidar_to_camera_point(boxes_corner[idx])\n",
    "\n",
    "    ret = []\n",
    "    for roi in boxes_corner:\n",
    "        if CORNER2CENTER_AVG:  # average version\n",
    "            roi = np.array(roi)\n",
    "            h = abs(np.sum(roi[:4, 1] - roi[4:, 1]) / 4)\n",
    "            w = np.sum(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[1, [0, 2]] - roi[2, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[7, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[5, [0, 2]] - roi[6, [0, 2]]) ** 2))\n",
    "            ) / 4\n",
    "            l = np.sum(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[1, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[2, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[5, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[6, [0, 2]] - roi[7, [0, 2]]) ** 2))\n",
    "            ) / 4\n",
    "            x = np.sum(roi[:, 0], axis=0) / 8\n",
    "            y = np.sum(roi[0:4, 1], axis=0) / 4\n",
    "            z = np.sum(roi[:, 2], axis=0) / 8\n",
    "            ry = np.sum(\n",
    "                math.atan2(roi[2, 0] - roi[1, 0], roi[2, 2] - roi[1, 2]) +\n",
    "                math.atan2(roi[6, 0] - roi[5, 0], roi[6, 2] - roi[5, 2]) +\n",
    "                math.atan2(roi[3, 0] - roi[0, 0], roi[3, 2] - roi[0, 2]) +\n",
    "                math.atan2(roi[7, 0] - roi[4, 0], roi[7, 2] - roi[4, 2]) +\n",
    "                math.atan2(roi[0, 2] - roi[1, 2], roi[1, 0] - roi[0, 0]) +\n",
    "                math.atan2(roi[4, 2] - roi[5, 2], roi[5, 0] - roi[4, 0]) +\n",
    "                math.atan2(roi[3, 2] - roi[2, 2], roi[2, 0] - roi[3, 0]) +\n",
    "                math.atan2(roi[7, 2] - roi[6, 2], roi[6, 0] - roi[7, 0])\n",
    "            ) / 8\n",
    "            if w > l:\n",
    "                w, l = l, w\n",
    "                ry = ry - np.pi / 2\n",
    "            elif l > w:\n",
    "                l, w = w, l\n",
    "                ry = ry - np.pi / 2\n",
    "            ret.append([x, y, z, h, w, l, ry])\n",
    "\n",
    "        else:  # max version\n",
    "            h = max(abs(roi[:4, 1] - roi[4:, 1]))\n",
    "            w = np.max(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[1, [0, 2]] - roi[2, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[7, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[5, [0, 2]] - roi[6, [0, 2]]) ** 2))\n",
    "            )\n",
    "            l = np.max(\n",
    "                np.sqrt(np.sum((roi[0, [0, 2]] - roi[1, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[2, [0, 2]] - roi[3, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[4, [0, 2]] - roi[5, [0, 2]]) ** 2)) +\n",
    "                np.sqrt(np.sum((roi[6, [0, 2]] - roi[7, [0, 2]]) ** 2))\n",
    "            )\n",
    "            x = np.sum(roi[:, 0], axis=0) / 8\n",
    "            y = np.sum(roi[0:4, 1], axis=0) / 4\n",
    "            z = np.sum(roi[:, 2], axis=0) / 8\n",
    "            ry = np.sum(\n",
    "                math.atan2(roi[2, 0] - roi[1, 0], roi[2, 2] - roi[1, 2]) +\n",
    "                math.atan2(roi[6, 0] - roi[5, 0], roi[6, 2] - roi[5, 2]) +\n",
    "                math.atan2(roi[3, 0] - roi[0, 0], roi[3, 2] - roi[0, 2]) +\n",
    "                math.atan2(roi[7, 0] - roi[4, 0], roi[7, 2] - roi[4, 2]) +\n",
    "                math.atan2(roi[0, 2] - roi[1, 2], roi[1, 0] - roi[0, 0]) +\n",
    "                math.atan2(roi[4, 2] - roi[5, 2], roi[5, 0] - roi[4, 0]) +\n",
    "                math.atan2(roi[3, 2] - roi[2, 2], roi[2, 0] - roi[3, 0]) +\n",
    "                math.atan2(roi[7, 2] - roi[6, 2], roi[6, 0] - roi[7, 0])\n",
    "            ) / 8\n",
    "            if w > l:\n",
    "                w, l = l, w\n",
    "                ry = angle_in_limit(ry + np.pi / 2)\n",
    "            ret.append([x, y, z, h, w, l, ry])\n",
    "\n",
    "    if coordinate == 'lidar':\n",
    "        ret = camera_to_lidar_box(np.array(ret))\n",
    "\n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "def point_transform(points, tx, ty, tz, rx=0, ry=0, rz=0):\n",
    "    # Input:\n",
    "    #   points: (N, 3)\n",
    "    #   rx/y/z: in radians\n",
    "    # Output:\n",
    "    #   points: (N, 3)\n",
    "    N = points.shape[0]\n",
    "    points = np.hstack([points, np.ones((N, 1))])\n",
    "\n",
    "    mat1 = np.eye(4)\n",
    "    mat1[3, 0:3] = tx, ty, tz\n",
    "    points = np.matmul(points, mat1)\n",
    "\n",
    "    if rx != 0:\n",
    "        mat = np.zeros((4, 4))\n",
    "        mat[0, 0] = 1\n",
    "        mat[3, 3] = 1\n",
    "        mat[1, 1] = np.cos(rx)\n",
    "        mat[1, 2] = -np.sin(rx)\n",
    "        mat[2, 1] = np.sin(rx)\n",
    "        mat[2, 2] = np.cos(rx)\n",
    "        points = np.matmul(points, mat)\n",
    "\n",
    "    if ry != 0:\n",
    "        mat = np.zeros((4, 4))\n",
    "        mat[1, 1] = 1\n",
    "        mat[3, 3] = 1\n",
    "        mat[0, 0] = np.cos(ry)\n",
    "        mat[0, 2] = np.sin(ry)\n",
    "        mat[2, 0] = -np.sin(ry)\n",
    "        mat[2, 2] = np.cos(ry)\n",
    "        points = np.matmul(points, mat)\n",
    "\n",
    "    if rz != 0:\n",
    "        mat = np.zeros((4, 4))\n",
    "        mat[2, 2] = 1\n",
    "        mat[3, 3] = 1\n",
    "        mat[0, 0] = np.cos(rz)\n",
    "        mat[0, 1] = -np.sin(rz)\n",
    "        mat[1, 0] = np.sin(rz)\n",
    "        mat[1, 1] = np.cos(rz)\n",
    "        points = np.matmul(points, mat)\n",
    "\n",
    "    return points[:, 0:3]\n",
    "\n",
    "\n",
    "def box_transform(boxes, tx, ty, tz, r=0, coordinate='lidar'):\n",
    "    # Input:\n",
    "    #   boxes: (N, 7) x y z h w l rz/y\n",
    "    # Output:\n",
    "    #   boxes: (N, 7) x y z h w l rz/y\n",
    "    boxes_corner = center_to_corner_box3d(boxes, coordinate=coordinate)  # (N, 8, 3)\n",
    "    for idx in range(len(boxes_corner)):\n",
    "        if coordinate == 'lidar':\n",
    "            boxes_corner[idx] = point_transform(boxes_corner[idx], tx, ty, tz, rz=r)\n",
    "        else:\n",
    "            boxes_corner[idx] = point_transform(boxes_corner[idx], tx, ty, tz, ry=r)\n",
    "\n",
    "    return corner_to_center_box3d(boxes_corner, coordinate=coordinate)\n",
    "\n",
    "\n",
    "def inverse_rigid_trans(Tr):\n",
    "    ''' Inverse a rigid body transform matrix (3x4 as [R|t])\n",
    "        [R'|-R't; 0|1]\n",
    "    '''\n",
    "    inv_Tr = np.zeros_like(Tr)  # 3x4\n",
    "    inv_Tr[0:3, 0:3] = np.transpose(Tr[0:3, 0:3])\n",
    "    inv_Tr[0:3, 3] = np.dot(-np.transpose(Tr[0:3, 0:3]), Tr[0:3, 3])\n",
    "    return inv_Tr\n",
    "\n",
    "\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms, p=1.0):\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        if np.random.random() <= self.p:\n",
    "            for t in self.transforms:\n",
    "                lidar, labels = t(lidar, labels)\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class OneOf(object):\n",
    "    def __init__(self, transforms, p=1.0):\n",
    "        self.transforms = transforms\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        if np.random.random() <= self.p:\n",
    "            choice = np.random.randint(low=0, high=len(self.transforms))\n",
    "            lidar, labels = self.transforms[choice](lidar, labels)\n",
    "\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class Random_Rotation(object):\n",
    "    def __init__(self, limit_angle=np.pi / 4, p=0.5):\n",
    "        self.limit_angle = limit_angle\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        \"\"\"\n",
    "        :param labels: # (N', 7) x, y, z, h, w, l, r\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.p:\n",
    "            angle = np.random.uniform(-self.limit_angle, self.limit_angle)\n",
    "            lidar[:, 0:3] = point_transform(lidar[:, 0:3], 0, 0, 0, rz=angle)\n",
    "            labels = box_transform(labels, 0, 0, 0, r=angle, coordinate='lidar')\n",
    "\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class Random_Scaling(object):\n",
    "    def __init__(self, scaling_range=(0.95, 1.05), p=0.5):\n",
    "        self.scaling_range = scaling_range\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, lidar, labels):\n",
    "        \"\"\"\n",
    "        :param labels: # (N', 7) x, y, z, h, w, l, r\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.p:\n",
    "            factor = np.random.uniform(self.scaling_range[0], self.scaling_range[0])\n",
    "            lidar[:, 0:3] = lidar[:, 0:3] * factor\n",
    "            labels[:, 0:6] = labels[:, 0:6] * factor\n",
    "\n",
    "        return lidar, labels\n",
    "\n",
    "\n",
    "class Cutout(object):\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "        Refer from: https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_holes, ratio, fill_value=0., p=1.0):\n",
    "        self.n_holes = n_holes\n",
    "        self.ratio = ratio\n",
    "        assert 0. <= fill_value <= 1., \"the fill value is in a range of 0 to 1\"\n",
    "        self.fill_value = fill_value\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        if np.random.random() <= self.p:\n",
    "            h = img.size(1)\n",
    "            w = img.size(2)\n",
    "\n",
    "            h_cutout = int(self.ratio * h)\n",
    "            w_cutout = int(self.ratio * w)\n",
    "\n",
    "            for n in range(self.n_holes):\n",
    "                y = np.random.randint(h)\n",
    "                x = np.random.randint(w)\n",
    "\n",
    "                y1 = np.clip(y - h_cutout // 2, 0, h)\n",
    "                y2 = np.clip(y + h_cutout // 2, 0, h)\n",
    "                x1 = np.clip(x - w_cutout // 2, 0, w)\n",
    "                x2 = np.clip(x + w_cutout // 2, 0, w)\n",
    "\n",
    "                img[:, y1: y2, x1: x2] = self.fill_value  # Zero out the selected area\n",
    "                # Remove targets that are in the selected area\n",
    "                keep_target = []\n",
    "                for target_idx, target in enumerate(targets):\n",
    "                    _, _, target_x, target_y, target_w, target_l, _, _ = target\n",
    "                    if (x1 <= target_x * w <= x2) and (y1 <= target_y * h <= y2):\n",
    "                        continue\n",
    "                    keep_target.append(target_idx)\n",
    "                targets = targets[keep_target]\n",
    "\n",
    "        return img, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155306d",
   "metadata": {
    "papermill": {
     "duration": 0.040345,
     "end_time": "2024-05-05T12:49:23.313500",
     "exception": false,
     "start_time": "2024-05-05T12:49:23.273155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eca1ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:23.444915Z",
     "iopub.status.busy": "2024-05-05T12:49:23.429408Z",
     "iopub.status.idle": "2024-05-05T12:49:23.634466Z",
     "shell.execute_reply": "2024-05-05T12:49:23.635040Z",
     "shell.execute_reply.started": "2021-12-13T06:44:51.886868Z"
    },
    "papermill": {
     "duration": 0.281539,
     "end_time": "2024-05-05T12:49:23.635222",
     "exception": false,
     "start_time": "2024-05-05T12:49:23.353683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "class Object3d(object):\n",
    "    ''' 3d object label '''\n",
    "\n",
    "    def __init__(self, label_file_line):\n",
    "        data = label_file_line.split(' ')\n",
    "        data[1:] = [float(x) for x in data[1:]]\n",
    "        # extract label, truncation, occlusion\n",
    "        self.type = data[0]  # 'Car', 'Pedestrian', ...\n",
    "        self.cls_id = self.cls_type_to_id(self.type)\n",
    "        self.truncation = data[1]  # truncated pixel ratio [0..1]\n",
    "        self.occlusion = int(data[2])  # 0=visible, 1=partly occluded, 2=fully occluded, 3=unknown\n",
    "        self.alpha = data[3]  # object observation angle [-pi..pi]\n",
    "\n",
    "        # extract 2d bounding box in 0-based coordinates\n",
    "        self.xmin = data[4]  # left\n",
    "        self.ymin = data[5]  # top\n",
    "        self.xmax = data[6]  # right\n",
    "        self.ymax = data[7]  # bottom\n",
    "        self.box2d = np.array([self.xmin, self.ymin, self.xmax, self.ymax])\n",
    "\n",
    "        # extract 3d bounding box information\n",
    "        self.h = data[8]  # box height\n",
    "        self.w = data[9]  # box width\n",
    "        self.l = data[10]  # box length (in meters)\n",
    "        self.t = (data[11], data[12], data[13])  # location (x,y,z) in camera coord.\n",
    "        self.dis_to_cam = np.linalg.norm(self.t)\n",
    "        self.ry = data[14]  # yaw angle (around Y-axis in camera coordinates) [-pi..pi]\n",
    "        self.score = data[15] if data.__len__() == 16 else -1.0\n",
    "        self.level_str = None\n",
    "        self.level = self.get_obj_level()\n",
    "\n",
    "    def cls_type_to_id(self, cls_type):\n",
    "        if cls_type not in CLASS_NAME_TO_ID.keys():\n",
    "            return -1\n",
    "\n",
    "        return CLASS_NAME_TO_ID[cls_type]\n",
    "\n",
    "    def get_obj_level(self):\n",
    "        height = float(self.box2d[3]) - float(self.box2d[1]) + 1\n",
    "\n",
    "        if height >= 40 and self.truncation <= 0.15 and self.occlusion <= 0:\n",
    "            self.level_str = 'Easy'\n",
    "            return 1  # Easy\n",
    "        elif height >= 25 and self.truncation <= 0.3 and self.occlusion <= 1:\n",
    "            self.level_str = 'Moderate'\n",
    "            return 2  # Moderate\n",
    "        elif height >= 25 and self.truncation <= 0.5 and self.occlusion <= 2:\n",
    "            self.level_str = 'Hard'\n",
    "            return 3  # Hard\n",
    "        else:\n",
    "            self.level_str = 'UnKnown'\n",
    "            return 4\n",
    "\n",
    "    def print_object(self):\n",
    "        print('Type, truncation, occlusion, alpha: %s, %d, %d, %f' % \\\n",
    "              (self.type, self.truncation, self.occlusion, self.alpha))\n",
    "        print('2d bbox (x0,y0,x1,y1): %f, %f, %f, %f' % \\\n",
    "              (self.xmin, self.ymin, self.xmax, self.ymax))\n",
    "        print('3d bbox h,w,l: %f, %f, %f' % \\\n",
    "              (self.h, self.w, self.l))\n",
    "        print('3d bbox location, ry: (%f, %f, %f), %f' % \\\n",
    "              (self.t[0], self.t[1], self.t[2], self.ry))\n",
    "\n",
    "    def to_kitti_format(self):\n",
    "        kitti_str = '%s %.2f %d %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f %.2f' \\\n",
    "                    % (self.type, self.truncation, int(self.occlusion), self.alpha, self.box2d[0], self.box2d[1],\n",
    "                       self.box2d[2], self.box2d[3], self.h, self.w, self.l, self.t[0], self.t[1], self.t[2],\n",
    "                       self.ry, self.score)\n",
    "        return kitti_str\n",
    "\n",
    "\n",
    "def read_label(label_filename):\n",
    "    lines = [line.rstrip() for line in open(label_filename)]\n",
    "    objects = [Object3d(line) for line in lines]\n",
    "    return objects\n",
    "\n",
    "\n",
    "class Calibration(object):\n",
    "    ''' Calibration matrices and utils\n",
    "        3d XYZ in <label>.txt are in rect camera coord.\n",
    "        2d box xy are in image2 coord\n",
    "        Points in <lidar>.bin are in Velodyne coord.\n",
    "        y_image2 = P^2_rect * x_rect\n",
    "        y_image2 = P^2_rect * R0_rect * Tr_velo_to_cam * x_velo\n",
    "        x_ref = Tr_velo_to_cam * x_velo\n",
    "        x_rect = R0_rect * x_ref\n",
    "        P^2_rect = [f^2_u,  0,      c^2_u,  -f^2_u b^2_x;\n",
    "                    0,      f^2_v,  c^2_v,  -f^2_v b^2_y;\n",
    "                    0,      0,      1,      0]\n",
    "                 = K * [1|t]\n",
    "        image2 coord:\n",
    "         ----> x-axis (u)\n",
    "        |\n",
    "        |\n",
    "        v y-axis (v)\n",
    "        velodyne coord:\n",
    "        front x, left y, up z\n",
    "        rect/ref camera coord:\n",
    "        right x, down y, front z\n",
    "        Ref (KITTI paper): http://www.cvlibs.net/publications/Geiger2013IJRR.pdf\n",
    "        TODO(rqi): do matrix multiplication only once for each projection.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, calib_filepath):\n",
    "        calibs = self.read_calib_file(calib_filepath)\n",
    "        # Projection matrix from rect camera coord to image2 coord\n",
    "        self.P2 = calibs['P2']\n",
    "        self.P2 = np.reshape(self.P2, [3, 4])\n",
    "        self.P3 = calibs['P3']\n",
    "        self.P3 = np.reshape(self.P3, [3, 4])\n",
    "        # Rigid transform from Velodyne coord to reference camera coord\n",
    "        self.V2C = calibs['Tr_velo2cam']\n",
    "        self.V2C = np.reshape(self.V2C, [3, 4])\n",
    "        # Rotation from reference camera coord to rect camera coord\n",
    "        self.R0 = calibs['R_rect']\n",
    "        self.R0 = np.reshape(self.R0, [3, 3])\n",
    "\n",
    "        # Camera intrinsics and extrinsics\n",
    "        self.c_u = self.P2[0, 2]\n",
    "        self.c_v = self.P2[1, 2]\n",
    "        self.f_u = self.P2[0, 0]\n",
    "        self.f_v = self.P2[1, 1]\n",
    "        self.b_x = self.P2[0, 3] / (-self.f_u)  # relative\n",
    "        self.b_y = self.P2[1, 3] / (-self.f_v)\n",
    "\n",
    "    def read_calib_file(self, filepath):\n",
    "        with open(filepath) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        obj = lines[2].strip().split(' ')[1:]\n",
    "        P2 = np.array(obj, dtype=np.float32)\n",
    "        obj = lines[3].strip().split(' ')[1:]\n",
    "        P3 = np.array(obj, dtype=np.float32)\n",
    "        obj = lines[4].strip().split(' ')[1:]\n",
    "        R0 = np.array(obj, dtype=np.float32)\n",
    "        obj = lines[5].strip().split(' ')[1:]\n",
    "        Tr_velo_to_cam = np.array(obj, dtype=np.float32)\n",
    "\n",
    "        return {'P2': P2.reshape(3, 4),\n",
    "                'P3': P3.reshape(3, 4),\n",
    "                'R_rect': R0.reshape(3, 3),\n",
    "                'Tr_velo2cam': Tr_velo_to_cam.reshape(3, 4)}\n",
    "\n",
    "    def cart2hom(self, pts_3d):\n",
    "        \"\"\"\n",
    "        :param pts: (N, 3 or 2)\n",
    "        :return pts_hom: (N, 4 or 3)\n",
    "        \"\"\"\n",
    "        pts_hom = np.hstack((pts_3d, np.ones((pts_3d.shape[0], 1), dtype=np.float32)))\n",
    "        return pts_hom\n",
    "\n",
    "\n",
    "def compute_radius(det_size, min_overlap=0.7):\n",
    "    height, width = det_size\n",
    "\n",
    "    a1 = 1\n",
    "    b1 = (height + width)\n",
    "    c1 = width * height * (1 - min_overlap) / (1 + min_overlap)\n",
    "    sq1 = np.sqrt(b1 ** 2 - 4 * a1 * c1)\n",
    "    r1 = (b1 + sq1) / 2\n",
    "\n",
    "    a2 = 4\n",
    "    b2 = 2 * (height + width)\n",
    "    c2 = (1 - min_overlap) * width * height\n",
    "    sq2 = np.sqrt(b2 ** 2 - 4 * a2 * c2)\n",
    "    r2 = (b2 + sq2) / 2\n",
    "\n",
    "    a3 = 4 * min_overlap\n",
    "    b3 = -2 * min_overlap * (height + width)\n",
    "    c3 = (min_overlap - 1) * width * height\n",
    "    sq3 = np.sqrt(b3 ** 2 - 4 * a3 * c3)\n",
    "    r3 = (b3 + sq3) / 2\n",
    "\n",
    "    return min(r1, r2, r3)\n",
    "\n",
    "\n",
    "def gaussian2D(shape, sigma=1):\n",
    "    m, n = [(ss - 1.) / 2. for ss in shape]\n",
    "    y, x = np.ogrid[-m:m + 1, -n:n + 1]\n",
    "    h = np.exp(-(x * x + y * y) / (2 * sigma * sigma))\n",
    "    h[h < np.finfo(h.dtype).eps * h.max()] = 0\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "def gen_hm_radius(heatmap, center, radius, k=1):\n",
    "    diameter = 2 * radius + 1\n",
    "    gaussian = gaussian2D((diameter, diameter), sigma=diameter / 6)\n",
    "\n",
    "    x, y = int(center[0]), int(center[1])\n",
    "\n",
    "    height, width = heatmap.shape[0:2]\n",
    "\n",
    "    left, right = min(x, radius), min(width - x, radius + 1)\n",
    "    top, bottom = min(y, radius), min(height - y, radius + 1)\n",
    "\n",
    "    masked_heatmap = heatmap[y - top:y + bottom, x - left:x + right]\n",
    "    masked_gaussian = gaussian[radius - top:radius + bottom, radius - left:radius + right]\n",
    "    if min(masked_gaussian.shape) > 0 and min(masked_heatmap.shape) > 0:  # TODO debug\n",
    "        np.maximum(masked_heatmap, masked_gaussian * k, out=masked_heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def get_filtered_lidar(lidar, boundary, labels=None):\n",
    "    minX = boundary['minX']\n",
    "    maxX = boundary['maxX']\n",
    "    minY = boundary['minY']\n",
    "    maxY = boundary['maxY']\n",
    "    minZ = boundary['minZ']\n",
    "    maxZ = boundary['maxZ']\n",
    "\n",
    "    # Remove the point out of range x,y,z\n",
    "    mask = np.where((lidar[:, 0] >= minX) & (lidar[:, 0] <= maxX) &\n",
    "                    (lidar[:, 1] >= minY) & (lidar[:, 1] <= maxY) &\n",
    "                    (lidar[:, 2] >= minZ) & (lidar[:, 2] <= maxZ))\n",
    "    lidar = lidar[mask]\n",
    "    lidar[:, 2] = lidar[:, 2] - minZ\n",
    "\n",
    "    if labels is not None:\n",
    "        label_x = (labels[:, 1] >= minX) & (labels[:, 1] < maxX)\n",
    "        label_y = (labels[:, 2] >= minY) & (labels[:, 2] < maxY)\n",
    "        label_z = (labels[:, 3] >= minZ) & (labels[:, 3] < maxZ)\n",
    "        mask_label = label_x & label_y & label_z\n",
    "        labels = labels[mask_label]\n",
    "        return lidar, labels\n",
    "    else:\n",
    "        return lidar\n",
    "\n",
    "\n",
    "def box3d_corners_to_center(box3d_corner):\n",
    "    # (N, 8, 3) -> (N, 7)\n",
    "    assert box3d_corner.ndim == 3\n",
    "\n",
    "    xyz = np.mean(box3d_corner, axis=1)\n",
    "\n",
    "    h = abs(np.mean(box3d_corner[:, 4:, 2] - box3d_corner[:, :4, 2], axis=1, keepdims=True))\n",
    "    w = (np.sqrt(np.sum((box3d_corner[:, 0, [0, 1]] - box3d_corner[:, 1, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 2, [0, 1]] - box3d_corner[:, 3, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 4, [0, 1]] - box3d_corner[:, 5, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 6, [0, 1]] - box3d_corner[:, 7, [0, 1]]) ** 2, axis=1, keepdims=True))) / 4\n",
    "\n",
    "    l = (np.sqrt(np.sum((box3d_corner[:, 0, [0, 1]] - box3d_corner[:, 3, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 1, [0, 1]] - box3d_corner[:, 2, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 4, [0, 1]] - box3d_corner[:, 7, [0, 1]]) ** 2, axis=1, keepdims=True)) +\n",
    "         np.sqrt(np.sum((box3d_corner[:, 5, [0, 1]] - box3d_corner[:, 6, [0, 1]]) ** 2, axis=1, keepdims=True))) / 4\n",
    "\n",
    "    yaw = (np.arctan2(box3d_corner[:, 2, 1] - box3d_corner[:, 1, 1],\n",
    "                      box3d_corner[:, 2, 0] - box3d_corner[:, 1, 0]) +\n",
    "           np.arctan2(box3d_corner[:, 3, 1] - box3d_corner[:, 0, 1],\n",
    "                      box3d_corner[:, 3, 0] - box3d_corner[:, 0, 0]) +\n",
    "           np.arctan2(box3d_corner[:, 2, 0] - box3d_corner[:, 3, 0],\n",
    "                      box3d_corner[:, 3, 1] - box3d_corner[:, 2, 1]) +\n",
    "           np.arctan2(box3d_corner[:, 1, 0] - box3d_corner[:, 0, 0],\n",
    "                      box3d_corner[:, 0, 1] - box3d_corner[:, 1, 1]))[:, np.newaxis] / 4\n",
    "\n",
    "    return np.concatenate([h, w, l, xyz, yaw], axis=1).reshape(-1, 7)\n",
    "\n",
    "\n",
    "def box3d_center_to_conners(box3d_center):\n",
    "    h, w, l, x, y, z, yaw = box3d_center\n",
    "    Box = np.array([[-l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2],\n",
    "                    [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2],\n",
    "                    [0, 0, 0, 0, h, h, h, h]])\n",
    "\n",
    "    rotMat = np.array([\n",
    "        [np.cos(yaw), -np.sin(yaw), 0.0],\n",
    "        [np.sin(yaw), np.cos(yaw), 0.0],\n",
    "        [0.0, 0.0, 1.0]])\n",
    "\n",
    "    velo_box = np.dot(rotMat, Box)\n",
    "    cornerPosInVelo = velo_box + np.tile(np.array([x, y, z]), (8, 1)).T\n",
    "    box3d_corner = cornerPosInVelo.transpose()\n",
    "\n",
    "    return box3d_corner.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5c51e",
   "metadata": {
    "papermill": {
     "duration": 0.039994,
     "end_time": "2024-05-05T12:49:23.716005",
     "exception": false,
     "start_time": "2024-05-05T12:49:23.676011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Birds Eye View Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "080c11ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:23.810740Z",
     "iopub.status.busy": "2024-05-05T12:49:23.805583Z",
     "iopub.status.idle": "2024-05-05T12:49:23.823100Z",
     "shell.execute_reply": "2024-05-05T12:49:23.822461Z",
     "shell.execute_reply.started": "2021-12-13T06:44:51.958872Z"
    },
    "papermill": {
     "duration": 0.066496,
     "end_time": "2024-05-05T12:49:23.823234",
     "exception": false,
     "start_time": "2024-05-05T12:49:23.756738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def makeBEVMap(PointCloud_, boundary):\n",
    "    Height = BEV_HEIGHT + 1\n",
    "    Width = BEV_WIDTH + 1\n",
    "\n",
    "    # Discretize Feature Map\n",
    "    PointCloud = np.copy(PointCloud_)\n",
    "    PointCloud[:, 0] = np.int_(np.floor(PointCloud[:, 0] / DISCRETIZATION))\n",
    "    PointCloud[:, 1] = np.int_(np.floor(PointCloud[:, 1] / DISCRETIZATION) + Width / 2)\n",
    "\n",
    "    # sort-3times\n",
    "    sorted_indices = np.lexsort((-PointCloud[:, 2], PointCloud[:, 1], PointCloud[:, 0]))\n",
    "    PointCloud = PointCloud[sorted_indices]\n",
    "    _, unique_indices, unique_counts = np.unique(PointCloud[:, 0:2], axis=0, return_index=True, return_counts=True)\n",
    "    PointCloud_top = PointCloud[unique_indices]\n",
    "\n",
    "    # Height Map, Intensity Map & Density Map\n",
    "    heightMap = np.zeros((Height, Width))\n",
    "    intensityMap = np.zeros((Height, Width))\n",
    "    densityMap = np.zeros((Height, Width))\n",
    "\n",
    "    # some important problem is image coordinate is (y,x), not (x,y)\n",
    "    max_height = float(np.abs(boundary['maxZ'] - boundary['minZ']))\n",
    "    heightMap[np.int_(PointCloud_top[:, 0]), np.int_(PointCloud_top[:, 1])] = PointCloud_top[:, 2] / max_height\n",
    "\n",
    "    normalizedCounts = np.minimum(1.0, np.log(unique_counts + 1) / np.log(64))\n",
    "    intensityMap[np.int_(PointCloud_top[:, 0]), np.int_(PointCloud_top[:, 1])] = PointCloud_top[:, 3]\n",
    "    densityMap[np.int_(PointCloud_top[:, 0]), np.int_(PointCloud_top[:, 1])] = normalizedCounts\n",
    "\n",
    "    RGB_Map = np.zeros((3, Height - 1, Width - 1))\n",
    "    RGB_Map[2, :, :] = densityMap[:BEV_HEIGHT, :BEV_WIDTH]  # r_map\n",
    "    RGB_Map[1, :, :] = heightMap[:BEV_HEIGHT, :BEV_WIDTH]  # g_map\n",
    "    RGB_Map[0, :, :] = intensityMap[:BEV_HEIGHT, :BEV_WIDTH]  # b_map\n",
    "\n",
    "    return RGB_Map\n",
    "\n",
    "\n",
    "# bev image coordinates format\n",
    "def get_corners(x, y, w, l, yaw):\n",
    "    bev_corners = np.zeros((4, 2), dtype=np.float32)\n",
    "    cos_yaw = np.cos(yaw)\n",
    "    sin_yaw = np.sin(yaw)\n",
    "    # front left\n",
    "    bev_corners[0, 0] = x - w / 2 * cos_yaw - l / 2 * sin_yaw\n",
    "    bev_corners[0, 1] = y - w / 2 * sin_yaw + l / 2 * cos_yaw\n",
    "\n",
    "    # rear left\n",
    "    bev_corners[1, 0] = x - w / 2 * cos_yaw + l / 2 * sin_yaw\n",
    "    bev_corners[1, 1] = y - w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "\n",
    "    # rear right\n",
    "    bev_corners[2, 0] = x + w / 2 * cos_yaw + l / 2 * sin_yaw\n",
    "    bev_corners[2, 1] = y + w / 2 * sin_yaw - l / 2 * cos_yaw\n",
    "\n",
    "    # front right\n",
    "    bev_corners[3, 0] = x + w / 2 * cos_yaw - l / 2 * sin_yaw\n",
    "    bev_corners[3, 1] = y + w / 2 * sin_yaw + l / 2 * cos_yaw\n",
    "\n",
    "    return bev_corners\n",
    "\n",
    "\n",
    "def drawRotatedBox(img, x, y, w, l, yaw, color):\n",
    "    bev_corners = get_corners(x, y, w, l, yaw)\n",
    "    corners_int = bev_corners.reshape(-1, 1, 2).astype(int)\n",
    "    cv2.polylines(img, [corners_int], True, color, 2)\n",
    "    corners_int = bev_corners.reshape(-1, 2)\n",
    "    cv2.line(img, (int(corners_int[0, 0]), int(corners_int[0, 1])), (int(corners_int[3, 0]), int(corners_int[3, 1])), (255, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577fac0",
   "metadata": {
    "papermill": {
     "duration": 0.040485,
     "end_time": "2024-05-05T12:49:23.905483",
     "exception": false,
     "start_time": "2024-05-05T12:49:23.864998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77a1747a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:24.039531Z",
     "iopub.status.busy": "2024-05-05T12:49:24.012150Z",
     "iopub.status.idle": "2024-05-05T12:49:24.046535Z",
     "shell.execute_reply": "2024-05-05T12:49:24.045977Z",
     "shell.execute_reply.started": "2021-12-13T06:44:51.985096Z"
    },
    "papermill": {
     "duration": 0.10072,
     "end_time": "2024-05-05T12:49:24.046667",
     "exception": false,
     "start_time": "2024-05-05T12:49:23.945947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "from builtins import int\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "class KittiDataset(Dataset):\n",
    "    def __init__(self, configs, mode='train', lidar_aug=None, hflip_prob=None, num_samples=None):\n",
    "        self.dataset_dir = configs.dataset_dir\n",
    "        self.input_size = configs.input_size\n",
    "        self.hm_size = configs.hm_size\n",
    "\n",
    "        self.num_classes = configs.num_classes\n",
    "        self.max_objects = configs.max_objects\n",
    "\n",
    "        assert mode in ['train', 'val', 'test'], 'Invalid mode: {}'.format(mode)\n",
    "        self.mode = mode\n",
    "        self.is_test = (self.mode == 'test')\n",
    "        sub_folder = 'testing' if self.is_test else 'training'\n",
    "\n",
    "        self.lidar_aug = lidar_aug\n",
    "        self.hflip_prob = hflip_prob\n",
    "\n",
    "        self.image_dir = os.path.join(self.dataset_dir, sub_folder, \"image_2\")\n",
    "        self.lidar_dir = os.path.join(self.dataset_dir, sub_folder, \"velodyne\")\n",
    "        self.calib_dir = os.path.join(self.dataset_dir, sub_folder, \"calib\")\n",
    "        self.label_dir = os.path.join(self.dataset_dir, sub_folder, \"label_2\")\n",
    "        split_txt_path = os.path.join(configs.root_dir, 'dataset', 'kitti', 'ImageSets', '{}.txt'.format(mode))\n",
    "        self.sample_id_list = [int(x.strip()) for x in open(split_txt_path).readlines()]\n",
    "\n",
    "        if num_samples is not None:\n",
    "            self.sample_id_list = self.sample_id_list[:num_samples]\n",
    "        self.num_samples = len(self.sample_id_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_id_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            return self.load_img_only(index)\n",
    "        else:\n",
    "            return self.load_img_with_targets(index)\n",
    "\n",
    "    def load_img_only(self, index):\n",
    "        \"\"\"Load only image for the testing phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        lidarData = get_filtered_lidar(lidarData, boundary)\n",
    "        bev_map = makeBEVMap(lidarData, boundary)\n",
    "        bev_map = torch.from_numpy(bev_map)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "        }\n",
    "\n",
    "        return metadatas, bev_map, img_rgb\n",
    "\n",
    "    def load_img_with_targets(self, index):\n",
    "        \"\"\"Load images and targets for the training and validation phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path = os.path.join(self.image_dir, '{:06d}.png'.format(sample_id))\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        calib = self.get_calib(sample_id)\n",
    "        labels, has_labels = self.get_label(sample_id)\n",
    "        if has_labels:\n",
    "            labels[:, 1:] = camera_to_lidar_box(labels[:, 1:], calib.V2C, calib.R0, calib.P2)\n",
    "\n",
    "        if self.lidar_aug:\n",
    "            lidarData, labels[:, 1:] = self.lidar_aug(lidarData, labels[:, 1:])\n",
    "\n",
    "        lidarData, labels = get_filtered_lidar(lidarData, boundary, labels)\n",
    "\n",
    "        bev_map = makeBEVMap(lidarData, boundary)\n",
    "        bev_map = torch.from_numpy(bev_map)\n",
    "\n",
    "        hflipped = False\n",
    "        if np.random.random() < self.hflip_prob:\n",
    "            hflipped = True\n",
    "            # C, H, W\n",
    "            bev_map = torch.flip(bev_map, [-1])\n",
    "\n",
    "        targets = self.build_targets(labels, hflipped)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "            'hflipped': hflipped\n",
    "        }\n",
    "\n",
    "        return metadatas, bev_map, targets\n",
    "\n",
    "    def get_image(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, '{:06d}.png'.format(idx))\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        return img_path, img\n",
    "\n",
    "    def get_calib(self, idx):\n",
    "        calib_file = os.path.join(self.calib_dir, '{:06d}.txt'.format(idx))\n",
    "        # assert os.path.isfile(calib_file)\n",
    "        return Calibration(calib_file)\n",
    "\n",
    "    def get_lidar(self, idx):\n",
    "        lidar_file = os.path.join(self.lidar_dir, '{:06d}.bin'.format(idx))\n",
    "        # assert os.path.isfile(lidar_file)\n",
    "        return np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "    def get_label(self, idx):\n",
    "        labels = []\n",
    "        label_path = os.path.join(self.label_dir, '{:06d}.txt'.format(idx))\n",
    "        for line in open(label_path, 'r'):\n",
    "            line = line.rstrip()\n",
    "            line_parts = line.split(' ')\n",
    "            obj_name = line_parts[0]  # 'Car', 'Pedestrian', ...\n",
    "            cat_id = int(CLASS_NAME_TO_ID[obj_name])\n",
    "            if cat_id <= -99:  # ignore Tram and Misc\n",
    "                continue\n",
    "            truncated = int(float(line_parts[1]))  # truncated pixel ratio [0..1]\n",
    "            occluded = int(line_parts[2])  # 0=visible, 1=partly occluded, 2=fully occluded, 3=unknown\n",
    "            alpha = float(line_parts[3])  # object observation angle [-pi..pi]\n",
    "            # xmin, ymin, xmax, ymax\n",
    "            bbox = np.array([float(line_parts[4]), float(line_parts[5]), float(line_parts[6]), float(line_parts[7])])\n",
    "            # height, width, length (h, w, l)\n",
    "            h, w, l = float(line_parts[8]), float(line_parts[9]), float(line_parts[10])\n",
    "            # location (x,y,z) in camera coord.\n",
    "            x, y, z = float(line_parts[11]), float(line_parts[12]), float(line_parts[13])\n",
    "            ry = float(line_parts[14])  # yaw angle (around Y-axis in camera coordinates) [-pi..pi]\n",
    "\n",
    "            object_label = [cat_id, x, y, z, h, w, l, ry]\n",
    "            labels.append(object_label)\n",
    "\n",
    "        if len(labels) == 0:\n",
    "            labels = np.zeros((1, 8), dtype=np.float32)\n",
    "            has_labels = False\n",
    "        else:\n",
    "            labels = np.array(labels, dtype=np.float32)\n",
    "            has_labels = True\n",
    "\n",
    "        return labels, has_labels\n",
    "\n",
    "    def build_targets(self, labels, hflipped):\n",
    "        minX = boundary['minX']\n",
    "        maxX = boundary['maxX']\n",
    "        minY = boundary['minY']\n",
    "        maxY = boundary['maxY']\n",
    "        minZ = boundary['minZ']\n",
    "        maxZ = boundary['maxZ']\n",
    "\n",
    "        num_objects = min(len(labels), self.max_objects)\n",
    "        hm_l, hm_w = self.hm_size\n",
    "\n",
    "        hm_main_center = np.zeros((self.num_classes, hm_l, hm_w), dtype=np.float32)\n",
    "        cen_offset = np.zeros((self.max_objects, 2), dtype=np.float32)\n",
    "        direction = np.zeros((self.max_objects, 2), dtype=np.float32)\n",
    "        z_coor = np.zeros((self.max_objects, 1), dtype=np.float32)\n",
    "        dimension = np.zeros((self.max_objects, 3), dtype=np.float32)\n",
    "\n",
    "        indices_center = np.zeros((self.max_objects), dtype=np.int64)\n",
    "        obj_mask = np.zeros((self.max_objects), dtype=np.uint8)\n",
    "\n",
    "        for k in range(num_objects):\n",
    "            cls_id, x, y, z, h, w, l, yaw = labels[k]\n",
    "            cls_id = int(cls_id)\n",
    "            # Invert yaw angle\n",
    "            yaw = -yaw\n",
    "            if not ((minX <= x <= maxX) and (minY <= y <= maxY) and (minZ <= z <= maxZ)):\n",
    "                continue\n",
    "            if (h <= 0) or (w <= 0) or (l <= 0):\n",
    "                continue\n",
    "\n",
    "            bbox_l = l / bound_size_x * hm_l\n",
    "            bbox_w = w / bound_size_y * hm_w\n",
    "            radius = compute_radius((math.ceil(bbox_l), math.ceil(bbox_w)))\n",
    "            radius = max(0, int(radius))\n",
    "\n",
    "            center_y = (x - minX) / bound_size_x * hm_l  # x --> y (invert to 2D image space)\n",
    "            center_x = (y - minY) / bound_size_y * hm_w  # y --> x\n",
    "            center = np.array([center_x, center_y], dtype=np.float32)\n",
    "\n",
    "            if hflipped:\n",
    "                center[0] = hm_w - center[0] - 1\n",
    "\n",
    "            center_int = center.astype(np.int32)\n",
    "            if cls_id < 0:\n",
    "                ignore_ids = [_ for _ in range(self.num_classes)] if cls_id == - 1 else [- cls_id - 2]\n",
    "                # Consider to make mask ignore\n",
    "                for cls_ig in ignore_ids:\n",
    "                    gen_hm_radius(hm_main_center[cls_ig], center_int, radius)\n",
    "                hm_main_center[ignore_ids, center_int[1], center_int[0]] = 0.9999\n",
    "                continue\n",
    "\n",
    "            # Generate heatmaps for main center\n",
    "            gen_hm_radius(hm_main_center[cls_id], center, radius)\n",
    "            # Index of the center\n",
    "            indices_center[k] = center_int[1] * hm_w + center_int[0]\n",
    "\n",
    "            # targets for center offset\n",
    "            cen_offset[k] = center - center_int\n",
    "\n",
    "            # targets for dimension\n",
    "            dimension[k, 0] = h\n",
    "            dimension[k, 1] = w\n",
    "            dimension[k, 2] = l\n",
    "\n",
    "            # targets for direction\n",
    "            direction[k, 0] = math.sin(float(yaw))  # im\n",
    "            direction[k, 1] = math.cos(float(yaw))  # re\n",
    "            # im -->> -im\n",
    "            if hflipped:\n",
    "                direction[k, 0] = - direction[k, 0]\n",
    "\n",
    "            # targets for depth\n",
    "            z_coor[k] = z - minZ\n",
    "\n",
    "            # Generate object masks\n",
    "            obj_mask[k] = 1\n",
    "\n",
    "        targets = {\n",
    "            'hm_cen': hm_main_center,\n",
    "            'cen_offset': cen_offset,\n",
    "            'direction': direction,\n",
    "            'z_coor': z_coor,\n",
    "            'dim': dimension,\n",
    "            'indices_center': indices_center,\n",
    "            'obj_mask': obj_mask,\n",
    "        }\n",
    "\n",
    "        return targets\n",
    "\n",
    "    def draw_img_with_label(self, index):\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        calib = self.get_calib(sample_id)\n",
    "        labels, has_labels = self.get_label(sample_id)\n",
    "        if has_labels:\n",
    "            labels[:, 1:] = camera_to_lidar_box(labels[:, 1:], calib.V2C, calib.R0, calib.P2)\n",
    "\n",
    "        if self.lidar_aug:\n",
    "            lidarData, labels[:, 1:] = self.lidar_aug(lidarData, labels[:, 1:])\n",
    "\n",
    "        lidarData, labels = get_filtered_lidar(lidarData, boundary, labels)\n",
    "        bev_map = makeBEVMap(lidarData, boundary)\n",
    "\n",
    "        return bev_map, labels, img_rgb, img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea61da0",
   "metadata": {
    "papermill": {
     "duration": 0.043926,
     "end_time": "2024-05-05T12:49:24.133824",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.089898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ff89d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:24.232854Z",
     "iopub.status.busy": "2024-05-05T12:49:24.232180Z",
     "iopub.status.idle": "2024-05-05T12:49:24.234958Z",
     "shell.execute_reply": "2024-05-05T12:49:24.234359Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.039643Z"
    },
    "papermill": {
     "duration": 0.057913,
     "end_time": "2024-05-05T12:49:24.235081",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.177168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_train_dataloader(configs):\n",
    "    \"\"\"Create dataloader for training\"\"\"\n",
    "    train_lidar_aug = OneOf([\n",
    "        Random_Rotation(limit_angle=np.pi / 4, p=1.0),\n",
    "        Random_Scaling(scaling_range=(0.95, 1.05), p=1.0),\n",
    "    ], p=0.66)\n",
    "    train_dataset = KittiDataset(configs, mode='train', lidar_aug=train_lidar_aug, hflip_prob=configs.hflip_prob,\n",
    "                                 num_samples=configs.num_samples)\n",
    "    train_sampler = None\n",
    "    if configs.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=configs.batch_size, shuffle=(train_sampler is None),\n",
    "                                  pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=train_sampler)\n",
    "\n",
    "    return train_dataloader, train_sampler\n",
    "\n",
    "\n",
    "def create_val_dataloader(configs):\n",
    "    \"\"\"Create dataloader for validation\"\"\"\n",
    "    val_sampler = None\n",
    "    val_dataset = KittiDataset(configs, mode='val', lidar_aug=None, hflip_prob=0., num_samples=configs.num_samples)\n",
    "    if configs.distributed:\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=configs.batch_size, shuffle=False,\n",
    "                                pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=val_sampler)\n",
    "\n",
    "    return val_dataloader\n",
    "\n",
    "\n",
    "def create_test_dataloader(configs):\n",
    "    \"\"\"Create dataloader for testing phase\"\"\"\n",
    "\n",
    "    test_dataset = KittiDataset(configs, mode='test', lidar_aug=None, hflip_prob=0., num_samples=configs.num_samples)\n",
    "    test_sampler = None\n",
    "    if configs.distributed:\n",
    "        test_sampler = torch.utils.data.distributed.DistributedSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=configs.batch_size, shuffle=False,\n",
    "                                 pin_memory=configs.pin_memory, num_workers=configs.num_workers, sampler=test_sampler)\n",
    "\n",
    "    return test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36b3074",
   "metadata": {
    "papermill": {
     "duration": 0.040484,
     "end_time": "2024-05-05T12:49:24.316988",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.276504",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcceb53f",
   "metadata": {
    "papermill": {
     "duration": 0.04113,
     "end_time": "2024-05-05T12:49:24.399043",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.357913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d865fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:24.490212Z",
     "iopub.status.busy": "2024-05-05T12:49:24.489524Z",
     "iopub.status.idle": "2024-05-05T12:49:24.492266Z",
     "shell.execute_reply": "2024-05-05T12:49:24.491616Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.057978Z"
    },
    "papermill": {
     "duration": 0.052447,
     "end_time": "2024-05-05T12:49:24.492435",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.439988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "class Logger():\n",
    "    \"\"\"\n",
    "        Create logger to save logs during training\n",
    "        Args:\n",
    "            logs_dir:\n",
    "            saved_fn:\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, logs_dir, saved_fn):\n",
    "        logger_fn = 'logger_{}.txt'.format(saved_fn)\n",
    "        logger_path = os.path.join(logs_dir, logger_fn)\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        # formatter = logging.Formatter('%(asctime)s:File %(module)s.py:Func %(funcName)s:Line %(lineno)d:%(levelname)s: %(message)s')\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s: %(module)s.py - %(funcName)s(), at Line %(lineno)d:%(levelname)s:\\n%(message)s')\n",
    "\n",
    "        file_handler = logging.FileHandler(logger_path)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        file_handler.setFormatter(formatter)\n",
    "\n",
    "        stream_handler = logging.StreamHandler()\n",
    "        stream_handler.setFormatter(formatter)\n",
    "\n",
    "        self.logger.addHandler(file_handler)\n",
    "        self.logger.addHandler(stream_handler)\n",
    "\n",
    "    def info(self, message):\n",
    "        self.logger.info(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf93c59",
   "metadata": {
    "papermill": {
     "duration": 0.04413,
     "end_time": "2024-05-05T12:49:24.579234",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.535104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pytorch Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d1f4bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:24.675247Z",
     "iopub.status.busy": "2024-05-05T12:49:24.674598Z",
     "iopub.status.idle": "2024-05-05T12:49:24.677224Z",
     "shell.execute_reply": "2024-05-05T12:49:24.676672Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.07131Z"
    },
    "papermill": {
     "duration": 0.054729,
     "end_time": "2024-05-05T12:49:24.677360",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.622631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "__all__ = ['convert2cpu', 'convert2cpu_long', 'to_cpu', 'reduce_tensor', 'to_python_float', '_sigmoid']\n",
    "\n",
    "\n",
    "def convert2cpu(gpu_matrix):\n",
    "    return torch.FloatTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
    "\n",
    "\n",
    "def convert2cpu_long(gpu_matrix):\n",
    "    return torch.LongTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
    "\n",
    "\n",
    "def to_cpu(tensor):\n",
    "    return tensor.detach().cpu()\n",
    "\n",
    "\n",
    "def reduce_tensor(tensor, world_size):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= world_size\n",
    "    return rt\n",
    "\n",
    "\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'):\n",
    "        return t.item()\n",
    "    else:\n",
    "        return t[0]\n",
    "\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return torch.clamp(x.sigmoid_(), min=1e-4, max=1 - 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0759c",
   "metadata": {
    "papermill": {
     "duration": 0.041434,
     "end_time": "2024-05-05T12:49:24.759391",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.717957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5760c728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:24.856683Z",
     "iopub.status.busy": "2024-05-05T12:49:24.849125Z",
     "iopub.status.idle": "2024-05-05T12:49:24.859484Z",
     "shell.execute_reply": "2024-05-05T12:49:24.858969Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.08503Z"
    },
    "papermill": {
     "duration": 0.059697,
     "end_time": "2024-05-05T12:49:24.859614",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.799917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def make_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    # or os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def get_message(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        return '\\t'.join(entries)\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def time_synchronized():\n",
    "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ec468",
   "metadata": {
    "papermill": {
     "duration": 0.040718,
     "end_time": "2024-05-05T12:49:24.941587",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.900869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ad3d42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:25.085658Z",
     "iopub.status.busy": "2024-05-05T12:49:25.048771Z",
     "iopub.status.idle": "2024-05-05T12:49:25.109471Z",
     "shell.execute_reply": "2024-05-05T12:49:25.108829Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.106593Z"
    },
    "papermill": {
     "duration": 0.12611,
     "end_time": "2024-05-05T12:49:25.109606",
     "exception": false,
     "start_time": "2024-05-05T12:49:24.983496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class _LRMomentumScheduler(lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, last_epoch=-1):\n",
    "        if last_epoch == -1:\n",
    "            for group in optimizer.param_groups:\n",
    "                group.setdefault('initial_momentum', group['momentum'])\n",
    "        else:\n",
    "            for i, group in enumerate(optimizer.param_groups):\n",
    "                if 'initial_momentum' not in group:\n",
    "                    raise KeyError(\"param 'initial_momentum' is not specified \"\n",
    "                                   \"in param_groups[{}] when resuming an optimizer\".format(i))\n",
    "        self.base_momentums = list(map(lambda group: group['initial_momentum'], optimizer.param_groups))\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_momentum(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.last_epoch = epoch\n",
    "        for param_group, lr, momentum in zip(self.optimizer.param_groups, self.get_lr(), self.get_momentum()):\n",
    "            param_group['lr'] = lr\n",
    "            param_group['momentum'] = momentum\n",
    "\n",
    "\n",
    "class ParameterUpdate(object):\n",
    "    \"\"\"A callable class used to define an arbitrary schedule defined by a list.\n",
    "    This object is designed to be passed to the LambdaLR or LambdaScheduler scheduler to apply\n",
    "    the given schedule.\n",
    "    Arguments:\n",
    "        params {list or numpy.array} -- List or numpy array defining parameter schedule.\n",
    "        base_param {float} -- Parameter value used to initialize the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, base_param):\n",
    "        self.params = np.hstack([params, 0])\n",
    "        self.base_param = base_param\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        return self.params[epoch] / self.base_param\n",
    "\n",
    "\n",
    "def apply_lambda(last_epoch, bases, lambdas):\n",
    "    return [base * lmbda(last_epoch) for lmbda, base in zip(lambdas, bases)]\n",
    "\n",
    "\n",
    "class LambdaScheduler(_LRMomentumScheduler):\n",
    "    \"\"\"Sets the learning rate and momentum of each parameter group to the initial lr and momentum\n",
    "    times a given function. When last_epoch=-1, sets initial lr and momentum to the optimizer\n",
    "    values.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        lr_lambda (function or list): A function which computes a multiplicative\n",
    "            factor given an integer parameter epoch, or a list of such\n",
    "            functions, one for each group in optimizer.param_groups.\n",
    "            Default: lambda x:x.\n",
    "        momentum_lambda (function or list): As for lr_lambda but applied to momentum.\n",
    "            Default: lambda x:x.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    Example:\n",
    "        >>> # Assuming optimizer has two groups.\n",
    "        >>> lr_lambda = [\n",
    "        ...     lambda epoch: epoch // 30,\n",
    "        ...     lambda epoch: 0.95 ** epoch\n",
    "        ... ]\n",
    "        >>> mom_lambda = [\n",
    "        ...     lambda epoch: max(0, (50 - epoch) // 50),\n",
    "        ...     lambda epoch: 0.99 ** epoch\n",
    "        ... ]\n",
    "        >>> scheduler = LambdaScheduler(optimizer, lr_lambda, mom_lambda)\n",
    "        >>> for epoch in range(100):\n",
    "        >>>     train(...)\n",
    "        >>>     validate(...)\n",
    "        >>>     scheduler.step()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, lr_lambda=lambda x: x, momentum_lambda=lambda x: x, last_epoch=-1):\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        if not isinstance(lr_lambda, (list, tuple)):\n",
    "            self.lr_lambdas = [lr_lambda] * len(optimizer.param_groups)\n",
    "        else:\n",
    "            if len(lr_lambda) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"Expected {} lr_lambdas, but got {}\".format(\n",
    "                    len(optimizer.param_groups), len(lr_lambda)))\n",
    "            self.lr_lambdas = list(lr_lambda)\n",
    "\n",
    "        if not isinstance(momentum_lambda, (list, tuple)):\n",
    "            self.momentum_lambdas = [momentum_lambda] * len(optimizer.param_groups)\n",
    "        else:\n",
    "            if len(momentum_lambda) != len(optimizer.param_groups):\n",
    "                raise ValueError(\"Expected {} momentum_lambdas, but got {}\".format(\n",
    "                    len(optimizer.param_groups), len(momentum_lambda)))\n",
    "            self.momentum_lambdas = list(momentum_lambda)\n",
    "\n",
    "        self.last_epoch = last_epoch\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the state of the scheduler as a :class:`dict`.\n",
    "        It contains an entry for every variable in self.__dict__ which\n",
    "        is not the optimizer.\n",
    "        The learning rate and momentum lambda functions will only be saved if they are\n",
    "        callable objects and not if they are functions or lambdas.\n",
    "        \"\"\"\n",
    "        state_dict = {key: value for key, value in self.__dict__.items()\n",
    "                      if key not in ('optimizer', 'lr_lambdas', 'momentum_lambdas')}\n",
    "        state_dict['lr_lambdas'] = [None] * len(self.lr_lambdas)\n",
    "        state_dict['momentum_lambdas'] = [None] * len(self.momentum_lambdas)\n",
    "\n",
    "        for idx, (lr_fn, mom_fn) in enumerate(zip(self.lr_lambdas, self.momentum_lambdas)):\n",
    "            if not isinstance(lr_fn, types.FunctionType):\n",
    "                state_dict['lr_lambdas'][idx] = lr_fn.__dict__.copy()\n",
    "            if not isinstance(mom_fn, types.FunctionType):\n",
    "                state_dict['momentum_lambdas'][idx] = mom_fn.__dict__.copy()\n",
    "\n",
    "        return state_dict\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"Loads the schedulers state.\n",
    "        Arguments:\n",
    "            state_dict (dict): scheduler state. Should be an object returned\n",
    "                from a call to :meth:`state_dict`.\n",
    "        \"\"\"\n",
    "        lr_lambdas = state_dict.pop('lr_lambdas')\n",
    "        momentum_lambdas = state_dict.pop('momentum_lambdas')\n",
    "        self.__dict__.update(state_dict)\n",
    "\n",
    "        for idx, fn in enumerate(lr_lambdas):\n",
    "            if fn is not None:\n",
    "                self.lr_lambdas[idx].__dict__.update(fn)\n",
    "\n",
    "        for idx, fn in enumerate(momentum_lambdas):\n",
    "            if fn is not None:\n",
    "                self.momentum_lambdas[idx].__dict__.update(fn)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return apply_lambda(self.last_epoch, self.base_lrs, self.lr_lambdas)\n",
    "\n",
    "    def get_momentum(self):\n",
    "        return apply_lambda(self.last_epoch, self.base_momentums, self.momentum_lambdas)\n",
    "\n",
    "\n",
    "class ParameterUpdate(object):\n",
    "    \"\"\"A callable class used to define an arbitrary schedule defined by a list.\n",
    "    This object is designed to be passed to the LambdaLR or LambdaScheduler scheduler to apply\n",
    "    the given schedule. If a base_param is zero, no updates are applied.\n",
    "    Arguments:\n",
    "        params {list or numpy.array} -- List or numpy array defining parameter schedule.\n",
    "        base_param {float} -- Parameter value used to initialize the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, base_param):\n",
    "        self.params = np.hstack([params, 0])\n",
    "        self.base_param = base_param\n",
    "\n",
    "        if base_param < 1e-12:\n",
    "            self.base_param = 1\n",
    "            self.params = self.params * 0.0 + 1.0\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        return self.params[epoch] / self.base_param\n",
    "\n",
    "\n",
    "class ListScheduler(LambdaScheduler):\n",
    "    \"\"\"Sets the learning rate and momentum of each parameter group to values defined by lists.\n",
    "    When last_epoch=-1, sets initial lr and momentum to the optimizer values. One of both of lr\n",
    "    and momentum schedules may be specified.\n",
    "    Note that the parameters used to initialize the optimizer are overriden by those defined by\n",
    "    this scheduler.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        lrs (list or numpy.ndarray): A list of learning rates, or a list of lists, one for each\n",
    "            parameter group. One- or two-dimensional numpy arrays may also be passed.\n",
    "        momentum (list or numpy.ndarray): A list of momentums, or a list of lists, one for each\n",
    "            parameter group. One- or two-dimensional numpy arrays may also be passed.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "    Example:\n",
    "        >>> # Assuming optimizer has two groups.\n",
    "        >>> lrs = [\n",
    "        ...     np.linspace(0.01, 0.1, 100),\n",
    "        ...     np.logspace(-2, 0, 100)\n",
    "        ... ]\n",
    "        >>> momentums = [\n",
    "        ...     np.linspace(0.85, 0.95, 100),\n",
    "        ...     np.linspace(0.8, 0.99, 100)\n",
    "        ... ]\n",
    "        >>> scheduler = ListScheduler(optimizer, lrs, momentums)\n",
    "        >>> for epoch in range(100):\n",
    "        >>>     train(...)\n",
    "        >>>     validate(...)\n",
    "        >>>     scheduler.step()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, lrs=None, momentums=None, last_epoch=-1):\n",
    "        groups = optimizer.param_groups\n",
    "        if lrs is None:\n",
    "            lr_lambda = lambda x: x\n",
    "        else:\n",
    "            lrs = np.array(lrs) if isinstance(lrs, (list, tuple)) else lrs\n",
    "            if len(lrs.shape) == 1:\n",
    "                lr_lambda = [ParameterUpdate(lrs, g['lr']) for g in groups]\n",
    "            else:\n",
    "                lr_lambda = [ParameterUpdate(l, g['lr']) for l, g in zip(lrs, groups)]\n",
    "\n",
    "        if momentums is None:\n",
    "            momentum_lambda = lambda x: x\n",
    "        else:\n",
    "            momentums = np.array(momentums) if isinstance(momentums, (list, tuple)) else momentums\n",
    "            if len(momentums.shape) == 1:\n",
    "                momentum_lambda = [ParameterUpdate(momentums, g['momentum']) for g in groups]\n",
    "            else:\n",
    "                momentum_lambda = [ParameterUpdate(l, g['momentum']) for l, g in zip(momentums, groups)]\n",
    "        super().__init__(optimizer, lr_lambda, momentum_lambda)\n",
    "\n",
    "\n",
    "class RangeFinder(ListScheduler):\n",
    "    \"\"\"Scheduler class that implements the LR range search specified in:\n",
    "        A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch\n",
    "        size, momentum, and weight decay. Leslie N. Smith, 2018, arXiv:1803.09820.\n",
    "    Logarithmically spaced learning rates from 1e-7 to 1 are searched. The number of increments in\n",
    "    that range is determined by 'epochs'.\n",
    "    Note that the parameters used to initialize the optimizer are overriden by those defined by\n",
    "    this scheduler.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        epochs (int): Number of epochs over which to run test.\n",
    "    Example:\n",
    "        >>> scheduler = RangeFinder(optimizer, 100)\n",
    "        >>> for epoch in range(100):\n",
    "        >>>     train(...)\n",
    "        >>>     validate(...)\n",
    "        >>>     scheduler.step()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, epochs):\n",
    "        lrs = np.logspace(-7, 0, epochs)\n",
    "        super().__init__(optimizer, lrs)\n",
    "\n",
    "\n",
    "class OneCyclePolicy(ListScheduler):\n",
    "    \"\"\"Scheduler class that implements the 1cycle policy search specified in:\n",
    "        A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch\n",
    "        size, momentum, and weight decay. Leslie N. Smith, 2018, arXiv:1803.09820.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        lr (float or list). Maximum learning rate in range. If a list of values is passed, they\n",
    "            should correspond to parameter groups.\n",
    "        epochs (int): The number of epochs to use during search.\n",
    "        momentum_rng (list). Optional upper and lower momentum values (may be both equal). Set to\n",
    "            None to run without momentum. Default: [0.85, 0.95]. If a list of lists is passed, they\n",
    "            should correspond to parameter groups.\n",
    "        phase_ratio (float): Fraction of epochs used for the increasing and decreasing phase of\n",
    "            the schedule. For example, if phase_ratio=0.45 and epochs=100, the learning rate will\n",
    "            increase from lr/10 to lr over 45 epochs, then decrease back to lr/10 over 45 epochs,\n",
    "            then decrease to lr/100 over the remaining 10 epochs. Default: 0.45.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, lr, epochs, momentum_rng=[0.85, 0.95], phase_ratio=0.45):\n",
    "        phase_epochs = int(phase_ratio * epochs)\n",
    "        if isinstance(lr, (list, tuple)):\n",
    "            lrs = [\n",
    "                np.hstack([\n",
    "                    np.linspace(l * 1e-1, l, phase_epochs),\n",
    "                    np.linspace(l, l * 1e-1, phase_epochs),\n",
    "                    np.linspace(l * 1e-1, l * 1e-2, epochs - 2 * phase_epochs),\n",
    "                ]) for l in lr\n",
    "            ]\n",
    "        else:\n",
    "            lrs = np.hstack([\n",
    "                np.linspace(lr * 1e-1, lr, phase_epochs),\n",
    "                np.linspace(lr, lr * 1e-1, phase_epochs),\n",
    "                np.linspace(lr * 1e-1, lr * 1e-2, epochs - 2 * phase_epochs),\n",
    "            ])\n",
    "\n",
    "        if momentum_rng is not None:\n",
    "            momentum_rng = np.array(momentum_rng)\n",
    "            if len(momentum_rng.shape) == 2:\n",
    "                for i, g in enumerate(optimizer.param_groups):\n",
    "                    g['momentum'] = momentum_rng[i][1]\n",
    "                momentums = [\n",
    "                    np.hstack([\n",
    "                        np.linspace(m[1], m[0], phase_epochs),\n",
    "                        np.linspace(m[0], m[1], phase_epochs),\n",
    "                        np.linspace(m[1], m[1], epochs - 2 * phase_epochs),\n",
    "                    ]) for m in momentum_rng\n",
    "                ]\n",
    "            else:\n",
    "                for i, g in enumerate(optimizer.param_groups):\n",
    "                    g['momentum'] = momentum_rng[1]\n",
    "                momentums = np.hstack([\n",
    "                    np.linspace(momentum_rng[1], momentum_rng[0], phase_epochs),\n",
    "                    np.linspace(momentum_rng[0], momentum_rng[1], phase_epochs),\n",
    "                    np.linspace(momentum_rng[1], momentum_rng[1], epochs - 2 * phase_epochs),\n",
    "                ])\n",
    "        else:\n",
    "            momentums = None\n",
    "\n",
    "        super().__init__(optimizer, lrs, momentums)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3776c",
   "metadata": {
    "papermill": {
     "duration": 0.040701,
     "end_time": "2024-05-05T12:49:25.191303",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.150602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedab3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:25.295458Z",
     "iopub.status.busy": "2024-05-05T12:49:25.294441Z",
     "iopub.status.idle": "2024-05-05T12:49:25.297069Z",
     "shell.execute_reply": "2024-05-05T12:49:25.296523Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.157877Z"
    },
    "papermill": {
     "duration": 0.065315,
     "end_time": "2024-05-05T12:49:25.297202",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.231887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_optimizer(configs, model):\n",
    "    \"\"\"Create optimizer for training process\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        train_params = [param for param in model.module.parameters() if param.requires_grad]\n",
    "    else:\n",
    "        train_params = [param for param in model.parameters() if param.requires_grad]\n",
    "\n",
    "    if configs.optimizer_type == 'sgd':\n",
    "        optimizer = torch.optim.SGD(train_params, lr=configs.lr, momentum=configs.momentum, nesterov=True)\n",
    "    elif configs.optimizer_type == 'adam':\n",
    "        optimizer = torch.optim.Adam(train_params, lr=configs.lr, weight_decay=configs.weight_decay)\n",
    "    else:\n",
    "        assert False, \"Unknown optimizer type\"\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def create_lr_scheduler(optimizer, configs):\n",
    "    \"\"\"Create learning rate scheduler for training process\"\"\"\n",
    "\n",
    "    if configs.lr_type == 'multi_step':\n",
    "        def multi_step_scheduler(i):\n",
    "            if i < configs.steps[0]:\n",
    "                factor = 1.\n",
    "            elif i < configs.steps[1]:\n",
    "                factor = 0.1\n",
    "            else:\n",
    "                factor = 0.01\n",
    "\n",
    "            return factor\n",
    "\n",
    "        lr_scheduler = LambdaLR(optimizer, multi_step_scheduler)\n",
    "\n",
    "    elif configs.lr_type == 'cosin':\n",
    "        # Scheduler https://arxiv.org/pdf/1812.01187.pdf\n",
    "        lf = lambda x: (((1 + math.cos(x * math.pi / configs.num_epochs)) / 2) ** 1.0) * 0.9 + 0.1  # cosine\n",
    "        lr_scheduler = LambdaLR(optimizer, lr_lambda=lf)\n",
    "    elif configs.lr_type == 'one_cycle':\n",
    "        lr_scheduler = OneCyclePolicy(optimizer, configs.lr, configs.num_epochs, momentum_rng=[0.85, 0.95],\n",
    "                                      phase_ratio=0.45)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    plot_lr_scheduler(optimizer, lr_scheduler, configs.num_epochs, save_dir=configs.logs_dir, lr_type=configs.lr_type)\n",
    "\n",
    "    return lr_scheduler\n",
    "\n",
    "\n",
    "def get_saved_state(model, optimizer, lr_scheduler, epoch, configs):\n",
    "    \"\"\"Get the information to save with checkpoints\"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        model_state_dict = model.module.state_dict()\n",
    "    else:\n",
    "        model_state_dict = model.state_dict()\n",
    "    utils_state_dict = {\n",
    "        'epoch': epoch,\n",
    "        'configs': configs,\n",
    "        'optimizer': copy.deepcopy(optimizer.state_dict()),\n",
    "        'lr_scheduler': copy.deepcopy(lr_scheduler.state_dict())\n",
    "    }\n",
    "\n",
    "    return model_state_dict, utils_state_dict\n",
    "\n",
    "\n",
    "def save_checkpoint(checkpoints_dir, saved_fn, model_state_dict, utils_state_dict, epoch):\n",
    "    \"\"\"Save checkpoint every epoch only is best model or after every checkpoint_freq epoch\"\"\"\n",
    "    model_save_path = os.path.join(checkpoints_dir, 'Model_{}_epoch_{}.pth'.format(saved_fn, epoch))\n",
    "    utils_save_path = os.path.join(checkpoints_dir, 'Utils_{}_epoch_{}.pth'.format(saved_fn, epoch))\n",
    "\n",
    "    torch.save(model_state_dict, model_save_path)\n",
    "    torch.save(utils_state_dict, utils_save_path)\n",
    "\n",
    "    print('save a checkpoint at {}'.format(model_save_path))\n",
    "\n",
    "\n",
    "def plot_lr_scheduler(optimizer, scheduler, num_epochs=300, save_dir='', lr_type=''):\n",
    "    # Plot LR simulating training for full num_epochs\n",
    "    optimizer, scheduler = copy.copy(optimizer), copy.copy(scheduler)  # do not modify originals\n",
    "    y = []\n",
    "    for _ in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        y.append(optimizer.param_groups[0]['lr'])\n",
    "    plt.plot(y, '.-', label='LR')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('LR')\n",
    "    plt.grid()\n",
    "    plt.xlim(0, num_epochs)\n",
    "    plt.ylim(0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, 'LR_{}.png'.format(lr_type)), dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461db2a",
   "metadata": {
    "papermill": {
     "duration": 0.040466,
     "end_time": "2024-05-05T12:49:25.378649",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.338183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cc67a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:25.499176Z",
     "iopub.status.busy": "2024-05-05T12:49:25.498127Z",
     "iopub.status.idle": "2024-05-05T12:49:25.500717Z",
     "shell.execute_reply": "2024-05-05T12:49:25.500248Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.179988Z"
    },
    "papermill": {
     "duration": 0.081705,
     "end_time": "2024-05-05T12:49:25.500886",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.419181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "def _nms(heat, kernel=3):\n",
    "    pad = (kernel - 1) // 2\n",
    "    hmax = F.max_pool2d(heat, (kernel, kernel), stride=1, padding=pad)\n",
    "    keep = (hmax == heat).float()\n",
    "\n",
    "    return heat * keep\n",
    "\n",
    "\n",
    "def _gather_feat(feat, ind, mask=None):\n",
    "    dim = feat.size(2)\n",
    "    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "    feat = feat.gather(1, ind)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(2).expand_as(feat)\n",
    "        feat = feat[mask]\n",
    "        feat = feat.view(-1, dim)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _transpose_and_gather_feat(feat, ind):\n",
    "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "    feat = _gather_feat(feat, ind)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _topk(scores, K=40):\n",
    "    batch, cat, height, width = scores.size()\n",
    "\n",
    "    topk_scores, topk_inds = torch.topk(scores.view(batch, cat, -1), K)\n",
    "\n",
    "    topk_inds = topk_inds % (height * width)\n",
    "    topk_ys = (torch.floor_divide(topk_inds, width)).float()\n",
    "    topk_xs = (topk_inds % width).int().float()\n",
    "\n",
    "    topk_score, topk_ind = torch.topk(topk_scores.view(batch, -1), K)\n",
    "    topk_clses = (torch.floor_divide(topk_ind, K)).int()\n",
    "    topk_inds = _gather_feat(topk_inds.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "    topk_ys = _gather_feat(topk_ys.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "    topk_xs = _gather_feat(topk_xs.view(batch, -1, 1), topk_ind).view(batch, K)\n",
    "\n",
    "    return topk_score, topk_inds, topk_clses, topk_ys, topk_xs\n",
    "\n",
    "\n",
    "def _topk_channel(scores, K=40):\n",
    "    batch, cat, height, width = scores.size()\n",
    "\n",
    "    topk_scores, topk_inds = torch.topk(scores.view(batch, cat, -1), K)\n",
    "\n",
    "    topk_inds = topk_inds % (height * width)\n",
    "    topk_ys = (topk_inds / width).int().float()\n",
    "    topk_xs = (topk_inds % width).int().float()\n",
    "\n",
    "    return topk_scores, topk_inds, topk_ys, topk_xs\n",
    "\n",
    "\n",
    "def decode(hm_cen, cen_offset, direction, z_coor, dim, K=40):\n",
    "    batch_size, num_classes, height, width = hm_cen.size()\n",
    "\n",
    "    hm_cen = _nms(hm_cen)\n",
    "    scores, inds, clses, ys, xs = _topk(hm_cen, K=K)\n",
    "    if cen_offset is not None:\n",
    "        cen_offset = _transpose_and_gather_feat(cen_offset, inds)\n",
    "        cen_offset = cen_offset.view(batch_size, K, 2)\n",
    "        xs = xs.view(batch_size, K, 1) + cen_offset[:, :, 0:1]\n",
    "        ys = ys.view(batch_size, K, 1) + cen_offset[:, :, 1:2]\n",
    "    else:\n",
    "        xs = xs.view(batch_size, K, 1) + 0.5\n",
    "        ys = ys.view(batch_size, K, 1) + 0.5\n",
    "\n",
    "    direction = _transpose_and_gather_feat(direction, inds)\n",
    "    direction = direction.view(batch_size, K, 2)\n",
    "    z_coor = _transpose_and_gather_feat(z_coor, inds)\n",
    "    z_coor = z_coor.view(batch_size, K, 1)\n",
    "    dim = _transpose_and_gather_feat(dim, inds)\n",
    "    dim = dim.view(batch_size, K, 3)\n",
    "    clses = clses.view(batch_size, K, 1).float()\n",
    "    scores = scores.view(batch_size, K, 1)\n",
    "\n",
    "    # (scores x 1, ys x 1, xs x 1, z_coor x 1, dim x 3, direction x 2, clses x 1)\n",
    "    # (scores-0:1, ys-1:2, xs-2:3, z_coor-3:4, dim-4:7, direction-7:9, clses-9:10)\n",
    "    # detections: [batch_size, K, 10]\n",
    "    detections = torch.cat([scores, xs, ys, z_coor, dim, direction, clses], dim=2)\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "def get_yaw(direction):\n",
    "    return np.arctan2(direction[:, 0:1], direction[:, 1:2])\n",
    "\n",
    "\n",
    "def post_processing(detections, num_classes=3, down_ratio=4, peak_thresh=0.2):\n",
    "    \"\"\"\n",
    "    :param detections: [batch_size, K, 10]\n",
    "    # (scores x 1, xs x 1, ys x 1, z_coor x 1, dim x 3, direction x 2, clses x 1)\n",
    "    # (scores-0:1, xs-1:2, ys-2:3, z_coor-3:4, dim-4:7, direction-7:9, clses-9:10)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TODO: Need to consider rescale to the original scale: x, y\n",
    "\n",
    "    ret = []\n",
    "    for i in range(detections.shape[0]):\n",
    "        top_preds = {}\n",
    "        classes = detections[i, :, -1]\n",
    "        for j in range(num_classes):\n",
    "            inds = (classes == j)\n",
    "            # x, y, z, h, w, l, yaw\n",
    "            top_preds[j] = np.concatenate([\n",
    "                detections[i, inds, 0:1],\n",
    "                detections[i, inds, 1:2] * down_ratio,\n",
    "                detections[i, inds, 2:3] * down_ratio,\n",
    "                detections[i, inds, 3:4],\n",
    "                detections[i, inds, 4:5],\n",
    "                detections[i, inds, 5:6] / bound_size_y * BEV_WIDTH,\n",
    "                detections[i, inds, 6:7] / bound_size_x * BEV_HEIGHT,\n",
    "                get_yaw(detections[i, inds, 7:9]).astype(np.float32)], axis=1)\n",
    "            # Filter by peak_thresh\n",
    "            if len(top_preds[j]) > 0:\n",
    "                keep_inds = (top_preds[j][:, 0] > peak_thresh)\n",
    "                top_preds[j] = top_preds[j][keep_inds]\n",
    "        ret.append(top_preds)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def draw_predictions(img, detections, num_classes=3):\n",
    "    for j in range(num_classes):\n",
    "        if len(detections[j]) > 0:\n",
    "            for det in detections[j]:\n",
    "                # (scores-0:1, x-1:2, y-2:3, z-3:4, dim-4:7, yaw-7:8)\n",
    "                _score, _x, _y, _z, _h, _w, _l, _yaw = det\n",
    "                drawRotatedBox(img, _x, _y, _w, _l, _yaw, colors[int(j)])\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def convert_det_to_real_values(detections, num_classes=3):\n",
    "    kitti_dets = []\n",
    "    for cls_id in range(num_classes):\n",
    "        if len(detections[cls_id]) > 0:\n",
    "            for det in detections[cls_id]:\n",
    "                # (scores-0:1, x-1:2, y-2:3, z-3:4, dim-4:7, yaw-7:8)\n",
    "                _score, _x, _y, _z, _h, _w, _l, _yaw = det\n",
    "                _yaw = -_yaw\n",
    "                x = _y / BEV_HEIGHT * bound_size_x + boundary['minX']\n",
    "                y = _x / BEV_WIDTH * bound_size_y + boundary['minY']\n",
    "                z = _z + boundary['minZ']\n",
    "                w = _w / BEV_WIDTH * bound_size_y\n",
    "                l = _l / BEV_HEIGHT * bound_size_x\n",
    "\n",
    "                kitti_dets.append([cls_id, x, y, z, _h, w, l, _yaw])\n",
    "\n",
    "    return np.array(kitti_dets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854140f1",
   "metadata": {
    "papermill": {
     "duration": 0.091846,
     "end_time": "2024-05-05T12:49:25.633438",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.541592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualization Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adb9d724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:25.747173Z",
     "iopub.status.busy": "2024-05-05T12:49:25.746144Z",
     "iopub.status.idle": "2024-05-05T12:49:25.748220Z",
     "shell.execute_reply": "2024-05-05T12:49:25.748656Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.21966Z"
    },
    "papermill": {
     "duration": 0.074731,
     "end_time": "2024-05-05T12:49:25.748845",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.674114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def roty(angle):\n",
    "    # Rotation about the y-axis.\n",
    "    c = np.cos(angle)\n",
    "    s = np.sin(angle)\n",
    "    return np.array([[c, 0, s],\n",
    "                     [0, 1, 0],\n",
    "                     [-s, 0, c]])\n",
    "\n",
    "\n",
    "def compute_box_3d(dim, location, ry):\n",
    "    # dim: 3\n",
    "    # location: 3\n",
    "    # ry: 1\n",
    "    # return: 8 x 3\n",
    "    R = roty(ry)\n",
    "    h, w, l = dim\n",
    "    x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]\n",
    "    y_corners = [0, 0, 0, 0, -h, -h, -h, -h]\n",
    "    z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]\n",
    "\n",
    "    corners = np.array([x_corners, y_corners, z_corners], dtype=np.float32)\n",
    "    corners_3d = np.dot(R, corners)\n",
    "    corners_3d = corners_3d + np.array(location, dtype=np.float32).reshape(3, 1)\n",
    "    return corners_3d.transpose(1, 0)\n",
    "\n",
    "\n",
    "def project_to_image(pts_3d, P):\n",
    "    # pts_3d: n x 3\n",
    "    # P: 3 x 4\n",
    "    # return: n x 2\n",
    "    pts_3d_homo = np.concatenate([pts_3d, np.ones((pts_3d.shape[0], 1), dtype=np.float32)], axis=1)\n",
    "    pts_2d = np.dot(P, pts_3d_homo.transpose(1, 0)).transpose(1, 0)\n",
    "    pts_2d = pts_2d[:, :2] / pts_2d[:, 2:]\n",
    "\n",
    "    return pts_2d.astype(np.int)\n",
    "\n",
    "\n",
    "def draw_box_3d_v2(image, qs, color=(255, 0, 255), thickness=2):\n",
    "    ''' Draw 3d bounding box in image\n",
    "        qs: (8,3) array of vertices for the 3d box in following order:\n",
    "            1 -------- 0\n",
    "           /|         /|\n",
    "          2 -------- 3 .\n",
    "          | |        | |\n",
    "          . 5 -------- 4\n",
    "          |/         |/\n",
    "          6 -------- 7\n",
    "    '''\n",
    "    qs = qs.astype(np.int32)\n",
    "    for k in range(0, 4):\n",
    "        # Ref: http://docs.enthought.com/mayavi/mayavi/auto/mlab_helper_functions.html\n",
    "        i, j = k, (k + 1) % 4\n",
    "        # use LINE_AA for opencv3\n",
    "        cv2.line(image, (qs[i, 0], qs[i, 1]), (qs[j, 0], qs[j, 1]), color, thickness)\n",
    "\n",
    "        i, j = k + 4, (k + 1) % 4 + 4\n",
    "        cv2.line(image, (qs[i, 0], qs[i, 1]), (qs[j, 0], qs[j, 1]), color, thickness)\n",
    "\n",
    "        i, j = k, k + 4\n",
    "        cv2.line(image, (qs[i, 0], qs[i, 1]), (qs[j, 0], qs[j, 1]), color, thickness)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def draw_box_3d(image, corners, color=(0, 0, 255)):\n",
    "    ''' Draw 3d bounding box in image\n",
    "        corners: (8,3) array of vertices for the 3d box in following order:\n",
    "            1 -------- 0\n",
    "           /|         /|\n",
    "          2 -------- 3 .\n",
    "          | |        | |\n",
    "          . 5 -------- 4\n",
    "          |/         |/\n",
    "          6 -------- 7\n",
    "    '''\n",
    "\n",
    "    face_idx = [[0, 1, 5, 4],\n",
    "                [1, 2, 6, 5],\n",
    "                [2, 3, 7, 6],\n",
    "                [3, 0, 4, 7]]\n",
    "    for ind_f in range(3, -1, -1):\n",
    "        f = face_idx[ind_f]\n",
    "        for j in range(4):\n",
    "            cv2.line(image, (corners[f[j], 0], corners[f[j], 1]),\n",
    "                     (corners[f[(j + 1) % 4], 0], corners[f[(j + 1) % 4], 1]), color, 2, lineType=cv2.LINE_AA)\n",
    "        if ind_f == 0:\n",
    "            cv2.line(image, (corners[f[0], 0], corners[f[0], 1]),\n",
    "                     (corners[f[2], 0], corners[f[2], 1]), color, 1, lineType=cv2.LINE_AA)\n",
    "            cv2.line(image, (corners[f[1], 0], corners[f[1], 1]),\n",
    "                     (corners[f[3], 0], corners[f[3], 1]), color, 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def show_rgb_image_with_boxes(img, labels, calib):\n",
    "    for box_idx, label in enumerate(labels):\n",
    "        cls_id, location, dim, ry = label[0], label[1:4], label[4:7], label[7]\n",
    "        if location[2] < 2.0:  # The object is too close to the camera, ignore it during visualization\n",
    "            continue\n",
    "        if cls_id < 0:\n",
    "            continue\n",
    "        corners_3d = compute_box_3d(dim, location, ry)\n",
    "        corners_2d = project_to_image(corners_3d, calib.P2)\n",
    "        img = draw_box_3d(img, corners_2d, color=colors[int(cls_id)])\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def merge_rgb_to_bev(img_rgb, img_bev, output_width):\n",
    "    img_rgb_h, img_rgb_w = img_rgb.shape[:2]\n",
    "    ratio_rgb = output_width / img_rgb_w\n",
    "    output_rgb_h = int(ratio_rgb * img_rgb_h)\n",
    "    ret_img_rgb = cv2.resize(img_rgb, (output_width, output_rgb_h))\n",
    "\n",
    "    img_bev_h, img_bev_w = img_bev.shape[:2]\n",
    "    ratio_bev = output_width / img_bev_w\n",
    "    output_bev_h = int(ratio_bev * img_bev_h)\n",
    "\n",
    "    ret_img_bev = cv2.resize(img_bev, (output_width, output_bev_h))\n",
    "\n",
    "    out_img = np.zeros((output_rgb_h + output_bev_h, output_width, 3), dtype=np.uint8)\n",
    "    # Upper: RGB --> BEV\n",
    "    out_img[:output_rgb_h, ...] = ret_img_rgb\n",
    "    out_img[output_rgb_h:, ...] = ret_img_bev\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29a51f6",
   "metadata": {
    "papermill": {
     "duration": 0.040093,
     "end_time": "2024-05-05T12:49:25.829372",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.789279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Demo Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3eb51d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:25.933121Z",
     "iopub.status.busy": "2024-05-05T12:49:25.927689Z",
     "iopub.status.idle": "2024-05-05T12:49:25.935698Z",
     "shell.execute_reply": "2024-05-05T12:49:25.935180Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.251115Z"
    },
    "papermill": {
     "duration": 0.062746,
     "end_time": "2024-05-05T12:49:25.935868",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.873122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from builtins import int\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "\n",
    "class Demo_KittiDataset(Dataset):\n",
    "    def __init__(self, configs):\n",
    "        self.dataset_dir = os.path.join(configs.dataset_dir, configs.foldername, configs.foldername[:10],\n",
    "                                        configs.foldername)\n",
    "        self.input_size = configs.input_size\n",
    "        self.hm_size = configs.hm_size\n",
    "\n",
    "        self.num_classes = configs.num_classes\n",
    "        self.max_objects = configs.max_objects\n",
    "\n",
    "        self.image_dir = os.path.join(self.dataset_dir, \"image_02\", \"data\")\n",
    "        self.lidar_dir = os.path.join(self.dataset_dir, \"velodyne_points\", \"data\")\n",
    "        self.label_dir = os.path.join(self.dataset_dir, \"label_2\", \"data\")\n",
    "        self.sample_id_list = sorted(glob(os.path.join(self.lidar_dir, '*.bin')))\n",
    "        self.sample_id_list = [float(os.path.basename(fn)[:-4]) for fn in self.sample_id_list]\n",
    "        self.num_samples = len(self.sample_id_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_id_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pass\n",
    "\n",
    "    def load_bevmap_front(self, index):\n",
    "        \"\"\"Load only image for the testing phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "        front_lidar = get_filtered_lidar(lidarData, boundary)\n",
    "        front_bevmap = makeBEVMap(front_lidar, boundary)\n",
    "        front_bevmap = torch.from_numpy(front_bevmap)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "        }\n",
    "\n",
    "        return metadatas, front_bevmap, img_rgb\n",
    "\n",
    "    def load_bevmap_front_vs_back(self, index):\n",
    "        \"\"\"Load only image for the testing phase\"\"\"\n",
    "        sample_id = int(self.sample_id_list[index])\n",
    "        img_path, img_rgb = self.get_image(sample_id)\n",
    "        lidarData = self.get_lidar(sample_id)\n",
    "\n",
    "        front_lidar = get_filtered_lidar(lidarData, boundary)\n",
    "        front_bevmap = makeBEVMap(front_lidar, boundary)\n",
    "        front_bevmap = torch.from_numpy(front_bevmap)\n",
    "\n",
    "        back_lidar = get_filtered_lidar(lidarData, boundary_back)\n",
    "        back_bevmap = makeBEVMap(back_lidar, boundary_back)\n",
    "        back_bevmap = torch.from_numpy(back_bevmap)\n",
    "\n",
    "        metadatas = {\n",
    "            'img_path': img_path,\n",
    "        }\n",
    "\n",
    "        return metadatas, front_bevmap, back_bevmap, img_rgb\n",
    "\n",
    "    def get_image(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, '{:010d}.png'.format(idx))\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        return img_path, img\n",
    "\n",
    "    def get_lidar(self, idx):\n",
    "        lidar_file = os.path.join(self.lidar_dir, '{:010d}.bin'.format(idx))\n",
    "        # assert os.path.isfile(lidar_file)\n",
    "        return np.fromfile(lidar_file, dtype=np.float32).reshape(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef370c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:26.048022Z",
     "iopub.status.busy": "2024-05-05T12:49:26.030437Z",
     "iopub.status.idle": "2024-05-05T12:49:45.716008Z",
     "shell.execute_reply": "2024-05-05T12:49:45.716506Z",
     "shell.execute_reply.started": "2021-12-13T06:44:52.271491Z"
    },
    "papermill": {
     "duration": 19.739997,
     "end_time": "2024-05-05T12:49:45.716697",
     "exception": false,
     "start_time": "2024-05-05T12:49:25.976700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\r\n",
      "  Downloading wget-3.2.zip (10 kB)\r\n",
      "Building wheels for collected packages: wget\r\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=37d356e6469d46c9d7033bb3bded00dd153561d43e3171ab309ce532f44f8fd4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\r\n",
      "Successfully built wget\r\n",
      "Installing collected packages: wget\r\n",
      "Successfully installed wget-3.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "--2024-05-05 12:49:40--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/demo/calib.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1616 (1.6K) [text/plain]\r\n",
      "Saving to: ./dataset/kitti/demo/calib.txt\r\n",
      "\r\n",
      "calib.txt           100%[===================>]   1.58K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2024-05-05 12:49:41 (22.8 MB/s) - ./dataset/kitti/demo/calib.txt saved [1616/1616]\r\n",
      "\r\n",
      "--2024-05-05 12:49:42--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/test.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 52626 (51K) [text/plain]\r\n",
      "Saving to: ./dataset/kitti/ImageSets/test.txt\r\n",
      "\r\n",
      "test.txt            100%[===================>]  51.39K  --.-KB/s    in 0.008s  \r\n",
      "\r\n",
      "2024-05-05 12:49:42 (6.13 MB/s) - ./dataset/kitti/ImageSets/test.txt saved [52626/52626]\r\n",
      "\r\n",
      "--2024-05-05 12:49:43--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/train.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 42000 (41K) [text/plain]\r\n",
      "Saving to: ./dataset/kitti/ImageSets/train.txt\r\n",
      "\r\n",
      "train.txt           100%[===================>]  41.02K  --.-KB/s    in 0.006s  \r\n",
      "\r\n",
      "2024-05-05 12:49:43 (6.16 MB/s) - ./dataset/kitti/ImageSets/train.txt saved [42000/42000]\r\n",
      "\r\n",
      "--2024-05-05 12:49:44--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/trainval.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 52367 (51K) [text/plain]\r\n",
      "Saving to: ./dataset/kitti/ImageSets/trainval.txt\r\n",
      "\r\n",
      "trainval.txt        100%[===================>]  51.14K  --.-KB/s    in 0.006s  \r\n",
      "\r\n",
      "2024-05-05 12:49:44 (7.94 MB/s) - ./dataset/kitti/ImageSets/trainval.txt saved [52367/52367]\r\n",
      "\r\n",
      "--2024-05-05 12:49:45--  https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/val.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 10367 (10K) [text/plain]\r\n",
      "Saving to: ./dataset/kitti/ImageSets/val.txt\r\n",
      "\r\n",
      "val.txt             100%[===================>]  10.12K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2024-05-05 12:49:45 (58.1 MB/s) - ./dataset/kitti/ImageSets/val.txt saved [10367/10367]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!mkdir -p ./dataset/kitti/demo\n",
    "!mkdir -p ./dataset/kitti/ImageSets\n",
    "\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/demo/calib.txt -P ./dataset/kitti/demo/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/test.txt -P ./dataset/kitti/ImageSets/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/train.txt -P ./dataset/kitti/ImageSets/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/trainval.txt -P ./dataset/kitti/ImageSets/\n",
    "!wget https://raw.githubusercontent.com/maudzung/SFA3D/master/dataset/kitti/ImageSets/val.txt -P ./dataset/kitti/ImageSets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec64fd0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:45.840648Z",
     "iopub.status.busy": "2024-05-05T12:49:45.830225Z",
     "iopub.status.idle": "2024-05-05T12:49:45.847366Z",
     "shell.execute_reply": "2024-05-05T12:49:45.846805Z",
     "shell.execute_reply.started": "2021-12-13T06:45:05.182517Z"
    },
    "papermill": {
     "duration": 0.081446,
     "end_time": "2024-05-05T12:49:45.847506",
     "exception": false,
     "start_time": "2024-05-05T12:49:45.766060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "import numpy as np\n",
    "import wget\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "\n",
    "def parse_demo_configs():\n",
    "    config_dict = {}\n",
    "    config_dict['saved_fn'] = 'fpn_resnet_18'\n",
    "    config_dict['arch'] = 'fpn_resnet_18'\n",
    "    config_dict['pretrained_path'] = './checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth'\n",
    "    config_dict['foldername'] = '2011_09_26_drive_0014_sync'\n",
    "    config_dict['K'] = 50\n",
    "    config_dict['gpu_idx'] = 0\n",
    "    config_dict['peak_thresh'] = 0.2\n",
    "    config_dict['output_width'] = 608\n",
    "    config_dict['no_cuda'] = False\n",
    "\n",
    "    configs = edict(config_dict)\n",
    "    configs.pin_memory = True\n",
    "    configs.distributed = False  # For testing on 1 GPU only\n",
    "\n",
    "    configs.input_size = (608, 608)\n",
    "    configs.hm_size = (152, 152)\n",
    "    configs.down_ratio = 4\n",
    "    configs.max_objects = 50\n",
    "\n",
    "    configs.imagenet_pretrained = False\n",
    "    configs.head_conv = 64\n",
    "    configs.num_classes = 3\n",
    "    configs.num_center_offset = 2\n",
    "    configs.num_z = 1\n",
    "    configs.num_dim = 3\n",
    "    configs.num_direction = 2  # sin, cos\n",
    "\n",
    "    configs.heads = {\n",
    "        'hm_cen': configs.num_classes,\n",
    "        'cen_offset': configs.num_center_offset,\n",
    "        'direction': configs.num_direction,\n",
    "        'z_coor': configs.num_z,\n",
    "        'dim': configs.num_dim\n",
    "    }\n",
    "\n",
    "    ####################################################################\n",
    "    ##############Dataset, Checkpoints, and results dir configs#########\n",
    "    ####################################################################\n",
    "    configs.root_dir = './'\n",
    "    configs.dataset_dir = os.path.join(configs.root_dir, 'dataset', 'kitti', 'demo')\n",
    "    configs.calib_path = os.path.join(configs.root_dir, 'dataset', 'kitti', 'demo', 'calib.txt')\n",
    "    configs.results_dir = os.path.join(configs.root_dir, 'results', configs.saved_fn)\n",
    "    make_folder(configs.results_dir)\n",
    "\n",
    "    return configs\n",
    "\n",
    "\n",
    "def download_and_unzip(demo_dataset_dir, download_url):\n",
    "    filename = download_url.split('/')[-1]\n",
    "    filepath = os.path.join(demo_dataset_dir, filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        print('The dataset have been downloaded')\n",
    "        return\n",
    "    print('\\nDownloading data for demonstration...')\n",
    "    wget.download(download_url, filepath)\n",
    "    print('\\nUnzipping the downloaded data...')\n",
    "    with zipfile.ZipFile(filepath, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(os.path.join(demo_dataset_dir, filename[:-4]))\n",
    "\n",
    "\n",
    "def do_detect(configs, model, bevmap, is_front):\n",
    "    if not is_front:\n",
    "        bevmap = torch.flip(bevmap, [1, 2])\n",
    "\n",
    "    input_bev_maps = bevmap.unsqueeze(0).to(configs.device, non_blocking=True).float()\n",
    "    t1 = time_synchronized()\n",
    "    outputs = model(input_bev_maps)\n",
    "    outputs['hm_cen'] = _sigmoid(outputs['hm_cen'])\n",
    "    outputs['cen_offset'] = _sigmoid(outputs['cen_offset'])\n",
    "    # detections size (batch_size, K, 10)\n",
    "    detections = decode(outputs['hm_cen'], outputs['cen_offset'], outputs['direction'], outputs['z_coor'],\n",
    "                        outputs['dim'], K=configs.K)\n",
    "    detections = detections.cpu().numpy().astype(np.float32)\n",
    "    detections = post_processing(detections, configs.num_classes, configs.down_ratio, configs.peak_thresh)\n",
    "    t2 = time_synchronized()\n",
    "    # Inference speed\n",
    "    fps = 1 / (t2 - t1)\n",
    "\n",
    "    return detections[0], bevmap, fps\n",
    "\n",
    "\n",
    "def write_credit(img, org_author=(500, 400), text_author='github.com/maudzung', org_fps=(50, 1000), fps=None):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontScale = 1\n",
    "    color = (255, 255, 255)\n",
    "    thickness = 2\n",
    "\n",
    "    cv2.putText(img, text_author, org_author, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "    cv2.putText(img, 'Speed: {:.1f} FPS'.format(fps), org_fps, font, fontScale, color, thickness, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8ae6c",
   "metadata": {
    "papermill": {
     "duration": 0.048703,
     "end_time": "2024-05-05T12:49:45.944941",
     "exception": false,
     "start_time": "2024-05-05T12:49:45.896238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c46381ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:46.080018Z",
     "iopub.status.busy": "2024-05-05T12:49:46.078982Z",
     "iopub.status.idle": "2024-05-05T12:49:46.082591Z",
     "shell.execute_reply": "2024-05-05T12:49:46.082073Z",
     "shell.execute_reply.started": "2021-12-13T06:45:05.206812Z"
    },
    "papermill": {
     "duration": 0.088648,
     "end_time": "2024-05-05T12:49:46.082722",
     "exception": false,
     "start_time": "2024-05-05T12:49:45.994074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def _gather_feat(feat, ind, mask=None):\n",
    "    dim = feat.size(2)\n",
    "    ind = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "    feat = feat.gather(1, ind)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(2).expand_as(feat)\n",
    "        feat = feat[mask]\n",
    "        feat = feat.view(-1, dim)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _transpose_and_gather_feat(feat, ind):\n",
    "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "    feat = _gather_feat(feat, ind)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def _neg_loss(pred, gt, alpha=2, beta=4):\n",
    "    ''' Modified focal loss. Exactly the same as CornerNet.\n",
    "        Runs faster and costs a little bit more memory\n",
    "      Arguments:\n",
    "        pred (batch x c x h x w)\n",
    "        gt_regr (batch x c x h x w)\n",
    "    '''\n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "\n",
    "    neg_weights = torch.pow(1 - gt, beta)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, alpha) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, alpha) * neg_weights * neg_inds\n",
    "\n",
    "    num_pos = pos_inds.float().sum()\n",
    "    pos_loss = pos_loss.sum()\n",
    "    neg_loss = neg_loss.sum()\n",
    "\n",
    "    if num_pos == 0:\n",
    "        loss = loss - neg_loss\n",
    "    else:\n",
    "        loss = loss - (pos_loss + neg_loss) / num_pos\n",
    "    return loss\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    '''nn.Module warpper for focal loss'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.neg_loss = _neg_loss\n",
    "\n",
    "    def forward(self, out, target):\n",
    "        return self.neg_loss(out, target)\n",
    "\n",
    "\n",
    "class L1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L1Loss, self).__init__()\n",
    "\n",
    "    def forward(self, output, mask, ind, target):\n",
    "        pred = _transpose_and_gather_feat(output, ind)\n",
    "        mask = mask.unsqueeze(2).expand_as(pred).float()\n",
    "        loss = F.l1_loss(pred * mask, target * mask, size_average=False)\n",
    "        loss = loss / (mask.sum() + 1e-4)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class L1Loss_Balanced(nn.Module):\n",
    "    \"\"\"Balanced L1 Loss\n",
    "    paper: https://arxiv.org/pdf/1904.02701.pdf (CVPR 2019)\n",
    "    Code refer from: https://github.com/OceanPang/Libra_R-CNN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.5, gamma=1.5, beta=1.0):\n",
    "        super(L1Loss_Balanced, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        assert beta > 0\n",
    "        self.beta = beta\n",
    "\n",
    "    def forward(self, output, mask, ind, target):\n",
    "        pred = _transpose_and_gather_feat(output, ind)\n",
    "        mask = mask.unsqueeze(2).expand_as(pred).float()\n",
    "        loss = self.balanced_l1_loss(pred * mask, target * mask)\n",
    "        loss = loss.sum() / (mask.sum() + 1e-4)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def balanced_l1_loss(self, pred, target):\n",
    "        assert pred.size() == target.size() and target.numel() > 0\n",
    "\n",
    "        diff = torch.abs(pred - target)\n",
    "        b = math.exp(self.gamma / self.alpha) - 1\n",
    "        loss = torch.where(diff < self.beta,\n",
    "                           self.alpha / b * (b * diff + 1) * torch.log(b * diff / self.beta + 1) - self.alpha * diff,\n",
    "                           self.gamma * diff + self.gamma / b - self.alpha * self.beta)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class Compute_Loss(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super(Compute_Loss, self).__init__()\n",
    "        self.device = device\n",
    "        self.focal_loss = FocalLoss()\n",
    "        self.l1_loss = L1Loss()\n",
    "        self.l1_loss_balanced = L1Loss_Balanced(alpha=0.5, gamma=1.5, beta=1.0)\n",
    "        self.weight_hm_cen = 1.\n",
    "        self.weight_z_coor, self.weight_cenoff, self.weight_dim, self.weight_direction = 1., 1., 1., 1.\n",
    "\n",
    "    def forward(self, outputs, tg):\n",
    "        # tg: targets\n",
    "        outputs['hm_cen'] = _sigmoid(outputs['hm_cen'])\n",
    "        outputs['cen_offset'] = _sigmoid(outputs['cen_offset'])\n",
    "\n",
    "        l_hm_cen = self.focal_loss(outputs['hm_cen'], tg['hm_cen'])\n",
    "        l_cen_offset = self.l1_loss(outputs['cen_offset'], tg['obj_mask'], tg['indices_center'], tg['cen_offset'])\n",
    "        l_direction = self.l1_loss(outputs['direction'], tg['obj_mask'], tg['indices_center'], tg['direction'])\n",
    "        # Apply the L1_loss balanced for z coor and dimension regression\n",
    "        l_z_coor = self.l1_loss_balanced(outputs['z_coor'], tg['obj_mask'], tg['indices_center'], tg['z_coor'])\n",
    "        l_dim = self.l1_loss_balanced(outputs['dim'], tg['obj_mask'], tg['indices_center'], tg['dim'])\n",
    "\n",
    "        total_loss = l_hm_cen * self.weight_hm_cen + l_cen_offset * self.weight_cenoff + \\\n",
    "                     l_dim * self.weight_dim + l_direction * self.weight_direction + \\\n",
    "                     l_z_coor * self.weight_z_coor\n",
    "\n",
    "        loss_stats = {\n",
    "            'total_loss': to_cpu(total_loss).item(),\n",
    "            'hm_cen_loss': to_cpu(l_hm_cen).item(),\n",
    "            'cen_offset_loss': to_cpu(l_cen_offset).item(),\n",
    "            'dim_loss': to_cpu(l_dim).item(),\n",
    "            'direction_loss': to_cpu(l_direction).item(),\n",
    "            'z_coor_loss': to_cpu(l_z_coor).item(),\n",
    "        }\n",
    "\n",
    "        return total_loss, loss_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3428b1",
   "metadata": {
    "papermill": {
     "duration": 0.046421,
     "end_time": "2024-05-05T12:49:46.177358",
     "exception": false,
     "start_time": "2024-05-05T12:49:46.130937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b26ad",
   "metadata": {
    "papermill": {
     "duration": 0.047032,
     "end_time": "2024-05-05T12:49:46.272039",
     "exception": false,
     "start_time": "2024-05-05T12:49:46.225007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## FPN ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "685a2ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:46.421198Z",
     "iopub.status.busy": "2024-05-05T12:49:46.397279Z",
     "iopub.status.idle": "2024-05-05T12:49:46.426092Z",
     "shell.execute_reply": "2024-05-05T12:49:46.426582Z",
     "shell.execute_reply.started": "2021-12-13T06:45:05.238949Z"
    },
    "papermill": {
     "duration": 0.106799,
     "end_time": "2024-05-05T12:49:46.426739",
     "exception": false,
     "start_time": "2024-05-05T12:49:46.319940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BN_MOMENTUM = 0.1\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class PoseResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, heads, head_conv, **kwargs):\n",
    "        self.inplanes = 64\n",
    "        self.deconv_with_bias = False\n",
    "        self.heads = heads\n",
    "\n",
    "        super(PoseResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.conv_up_level1 = nn.Conv2d(768, 256, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_up_level2 = nn.Conv2d(384, 128, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_up_level3 = nn.Conv2d(192, 64, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        fpn_channels = [256, 128, 64]\n",
    "        for fpn_idx, fpn_c in enumerate(fpn_channels):\n",
    "            for head in sorted(self.heads):\n",
    "                num_output = self.heads[head]\n",
    "                if head_conv > 0:\n",
    "                    fc = nn.Sequential(\n",
    "                        nn.Conv2d(fpn_c, head_conv, kernel_size=3, padding=1, bias=True),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Conv2d(head_conv, num_output, kernel_size=1, stride=1, padding=0))\n",
    "                else:\n",
    "                    fc = nn.Conv2d(in_channels=fpn_c, out_channels=num_output, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "                self.__setattr__('fpn{}_{}'.format(fpn_idx, head), fc)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, input_h, input_w = x.size()\n",
    "        hm_h, hm_w = input_h // 4, input_w // 4\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        out_layer1 = self.layer1(x)\n",
    "        out_layer2 = self.layer2(out_layer1)\n",
    "\n",
    "        out_layer3 = self.layer3(out_layer2)\n",
    "\n",
    "        out_layer4 = self.layer4(out_layer3)\n",
    "\n",
    "        # up_level1: torch.Size([b, 512, 14, 14])\n",
    "        up_level1 = F.interpolate(out_layer4, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        concat_level1 = torch.cat((up_level1, out_layer3), dim=1)\n",
    "        # up_level2: torch.Size([b, 256, 28, 28])\n",
    "        up_level2 = F.interpolate(self.conv_up_level1(concat_level1), scale_factor=2, mode='bilinear',\n",
    "                                  align_corners=True)\n",
    "\n",
    "        concat_level2 = torch.cat((up_level2, out_layer2), dim=1)\n",
    "        # up_level3: torch.Size([b, 128, 56, 56]),\n",
    "        up_level3 = F.interpolate(self.conv_up_level2(concat_level2), scale_factor=2, mode='bilinear',\n",
    "                                  align_corners=True)\n",
    "        # up_level4: torch.Size([b, 64, 56, 56])\n",
    "        up_level4 = self.conv_up_level3(torch.cat((up_level3, out_layer1), dim=1))\n",
    "\n",
    "        ret = {}\n",
    "        for head in self.heads:\n",
    "            temp_outs = []\n",
    "            for fpn_idx, fdn_input in enumerate([up_level2, up_level3, up_level4]):\n",
    "                fpn_out = self.__getattr__('fpn{}_{}'.format(fpn_idx, head))(fdn_input)\n",
    "                _, _, fpn_out_h, fpn_out_w = fpn_out.size()\n",
    "                # Make sure the added features having same size of heatmap output\n",
    "                if (fpn_out_w != hm_w) or (fpn_out_h != hm_h):\n",
    "                    fpn_out = F.interpolate(fpn_out, size=(hm_h, hm_w))\n",
    "                temp_outs.append(fpn_out)\n",
    "            # Take the softmax in the keypoint feature pyramid network\n",
    "            final_out = self.apply_kfpn(temp_outs)\n",
    "\n",
    "            ret[head] = final_out\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def apply_kfpn(self, outs):\n",
    "        outs = torch.cat([out.unsqueeze(-1) for out in outs], dim=-1)\n",
    "        softmax_outs = F.softmax(outs, dim=-1)\n",
    "        ret_outs = (outs * softmax_outs).sum(dim=-1)\n",
    "        return ret_outs\n",
    "\n",
    "    def init_weights(self, num_layers, pretrained=True):\n",
    "        if pretrained:\n",
    "            # TODO: Check initial weights for head later\n",
    "            for fpn_idx in [0, 1, 2]:  # 3 FPN layers\n",
    "                for head in self.heads:\n",
    "                    final_layer = self.__getattr__('fpn{}_{}'.format(fpn_idx, head))\n",
    "                    for i, m in enumerate(final_layer.modules()):\n",
    "                        if isinstance(m, nn.Conv2d):\n",
    "                            # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                            # print('=> init {}.weight as normal(0, 0.001)'.format(name))\n",
    "                            # print('=> init {}.bias as 0'.format(name))\n",
    "                            if m.weight.shape[0] == self.heads[head]:\n",
    "                                if 'hm' in head:\n",
    "                                    nn.init.constant_(m.bias, -2.19)\n",
    "                                else:\n",
    "                                    nn.init.normal_(m.weight, std=0.001)\n",
    "                                    nn.init.constant_(m.bias, 0)\n",
    "            # pretrained_state_dict = torch.load(pretrained)\n",
    "            url = model_urls['resnet{}'.format(num_layers)]\n",
    "            pretrained_state_dict = model_zoo.load_url(url)\n",
    "            print('=> loading pretrained model {}'.format(url))\n",
    "            self.load_state_dict(pretrained_state_dict, strict=False)\n",
    "\n",
    "\n",
    "resnet_spec = {18: (BasicBlock, [2, 2, 2, 2]),\n",
    "               34: (BasicBlock, [3, 4, 6, 3]),\n",
    "               50: (Bottleneck, [3, 4, 6, 3]),\n",
    "               101: (Bottleneck, [3, 4, 23, 3]),\n",
    "               152: (Bottleneck, [3, 8, 36, 3])}\n",
    "\n",
    "\n",
    "def get_pose_net(num_layers, heads, head_conv, imagenet_pretrained):\n",
    "    block_class, layers = resnet_spec[num_layers]\n",
    "\n",
    "    model = PoseResNet(block_class, layers, heads, head_conv=head_conv)\n",
    "    model.init_weights(num_layers, pretrained=imagenet_pretrained)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a51c40",
   "metadata": {
    "papermill": {
     "duration": 0.047102,
     "end_time": "2024-05-05T12:49:46.521397",
     "exception": false,
     "start_time": "2024-05-05T12:49:46.474295",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0213f7d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:46.630272Z",
     "iopub.status.busy": "2024-05-05T12:49:46.629532Z",
     "iopub.status.idle": "2024-05-05T12:49:46.632289Z",
     "shell.execute_reply": "2024-05-05T12:49:46.631648Z",
     "shell.execute_reply.started": "2021-12-13T06:45:05.287838Z"
    },
    "papermill": {
     "duration": 0.063592,
     "end_time": "2024-05-05T12:49:46.632417",
     "exception": false,
     "start_time": "2024-05-05T12:49:46.568825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def create_model(configs):\n",
    "    \"\"\"Create model based on architecture name\"\"\"\n",
    "    try:\n",
    "        arch_parts = configs.arch.split('_')\n",
    "        num_layers = int(arch_parts[-1])\n",
    "    except:\n",
    "        raise ValueError\n",
    "    if 'fpn_resnet' in configs.arch:\n",
    "        print('using ResNet architecture with feature pyramid')\n",
    "        model = get_pose_net(num_layers=num_layers, heads=configs.heads, head_conv=configs.head_conv,\n",
    "                             imagenet_pretrained=configs.imagenet_pretrained)\n",
    "    else:\n",
    "        assert False, 'Undefined model backbone'\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_num_parameters(model):\n",
    "    \"\"\"Count number of trained parameters of the model\"\"\"\n",
    "    if hasattr(model, 'module'):\n",
    "        num_parameters = sum(p.numel() for p in model.module.parameters() if p.requires_grad)\n",
    "    else:\n",
    "        num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    return num_parameters\n",
    "\n",
    "\n",
    "def make_data_parallel(model, configs):\n",
    "    if configs.distributed:\n",
    "        # For multiprocessing distributed, DistributedDataParallel constructor\n",
    "        # should always set the single device scope, otherwise,\n",
    "        # DistributedDataParallel will use all available devices.\n",
    "        if configs.gpu_idx is not None:\n",
    "            torch.cuda.set_device(configs.gpu_idx)\n",
    "            model.cuda(configs.gpu_idx)\n",
    "            # When using a single GPU per process and per\n",
    "            # DistributedDataParallel, we need to divide the batch size\n",
    "            # ourselves based on the total number of GPUs we have\n",
    "            configs.batch_size = int(configs.batch_size / configs.ngpus_per_node)\n",
    "            configs.num_workers = int((configs.num_workers + configs.ngpus_per_node - 1) / configs.ngpus_per_node)\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[configs.gpu_idx])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # DistributedDataParallel will divide and allocate batch_size to all\n",
    "            # available GPUs if device_ids are not set\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif configs.gpu_idx is not None:\n",
    "        torch.cuda.set_device(configs.gpu_idx)\n",
    "        model = model.cuda(configs.gpu_idx)\n",
    "    else:\n",
    "        # DataParallel will divide and allocate batch_size to all available GPUs\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5fcae",
   "metadata": {
    "papermill": {
     "duration": 0.047623,
     "end_time": "2024-05-05T12:49:46.730000",
     "exception": false,
     "start_time": "2024-05-05T12:49:46.682377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82b9ac64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:46.878101Z",
     "iopub.status.busy": "2024-05-05T12:49:46.848841Z",
     "iopub.status.idle": "2024-05-05T12:49:47.073241Z",
     "shell.execute_reply": "2024-05-05T12:49:47.072613Z",
     "shell.execute_reply.started": "2021-12-13T06:45:05.30341Z"
    },
    "papermill": {
     "duration": 0.295919,
     "end_time": "2024-05-05T12:49:47.073388",
     "exception": false,
     "start_time": "2024-05-05T12:49:46.777469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data.distributed\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def main():\n",
    "    configs = parse_configs()\n",
    "\n",
    "    # Re-produce results\n",
    "    if configs.seed is not None:\n",
    "        random.seed(configs.seed)\n",
    "        np.random.seed(configs.seed)\n",
    "        torch.manual_seed(configs.seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    if configs.gpu_idx is not None:\n",
    "        print('You have chosen a specific GPU. This will completely disable data parallelism.')\n",
    "\n",
    "    if configs.dist_url == \"env://\" and configs.world_size == -1:\n",
    "        configs.world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "\n",
    "    configs.distributed = configs.world_size > 1 or configs.multiprocessing_distributed\n",
    "\n",
    "    if configs.multiprocessing_distributed:\n",
    "        configs.world_size = configs.ngpus_per_node * configs.world_size\n",
    "        mp.spawn(main_worker, nprocs=configs.ngpus_per_node, args=(configs,))\n",
    "    else:\n",
    "        main_worker(configs.gpu_idx, configs)\n",
    "\n",
    "\n",
    "def main_worker(gpu_idx, configs):\n",
    "    configs.gpu_idx = gpu_idx\n",
    "    configs.device = torch.device('cpu' if configs.gpu_idx is None else 'cuda:{}'.format(configs.gpu_idx))\n",
    "\n",
    "    if configs.distributed:\n",
    "        if configs.dist_url == \"env://\" and configs.rank == -1:\n",
    "            configs.rank = int(os.environ[\"RANK\"])\n",
    "        if configs.multiprocessing_distributed:\n",
    "            # For multiprocessing distributed training, rank needs to be the\n",
    "            # global rank among all the processes\n",
    "            configs.rank = configs.rank * configs.ngpus_per_node + gpu_idx\n",
    "\n",
    "        dist.init_process_group(backend=configs.dist_backend, init_method=configs.dist_url,\n",
    "                                world_size=configs.world_size, rank=configs.rank)\n",
    "        configs.subdivisions = int(64 / configs.batch_size / configs.ngpus_per_node)\n",
    "    else:\n",
    "        configs.subdivisions = int(64 / configs.batch_size)\n",
    "\n",
    "    configs.is_master_node = (not configs.distributed) or (\n",
    "            configs.distributed and (configs.rank % configs.ngpus_per_node == 0))\n",
    "\n",
    "    if configs.is_master_node:\n",
    "        logger = Logger(configs.logs_dir, configs.saved_fn)\n",
    "        logger.info('>>> Created a new logger')\n",
    "        logger.info('>>> configs: {}'.format(configs))\n",
    "        tb_writer = SummaryWriter(log_dir=os.path.join(configs.logs_dir, 'tensorboard'))\n",
    "    else:\n",
    "        logger = None\n",
    "        tb_writer = None\n",
    "\n",
    "    # model\n",
    "    model = create_model(configs)\n",
    "\n",
    "    # load weight from a checkpoint\n",
    "    if configs.pretrained_path is not None:\n",
    "        assert os.path.isfile(configs.pretrained_path), \"=> no checkpoint found at '{}'\".format(configs.pretrained_path)\n",
    "        model.load_state_dict(torch.load(configs.pretrained_path, map_location='cpu'))\n",
    "        if logger is not None:\n",
    "            logger.info('loaded pretrained model at {}'.format(configs.pretrained_path))\n",
    "\n",
    "    # resume weights of model from a checkpoint\n",
    "    if configs.resume_path is not None:\n",
    "        assert os.path.isfile(configs.resume_path), \"=> no checkpoint found at '{}'\".format(configs.resume_path)\n",
    "        model.load_state_dict(torch.load(configs.resume_path, map_location='cpu'))\n",
    "        if logger is not None:\n",
    "            logger.info('resume training model from checkpoint {}'.format(configs.resume_path))\n",
    "\n",
    "    # Data Parallel\n",
    "    model = make_data_parallel(model, configs)\n",
    "\n",
    "    # Make sure to create optimizer after moving the model to cuda\n",
    "    optimizer = create_optimizer(configs, model)\n",
    "    lr_scheduler = create_lr_scheduler(optimizer, configs)\n",
    "    configs.step_lr_in_epoch = False if configs.lr_type in ['multi_step', 'cosin', 'one_cycle'] else True\n",
    "\n",
    "    # resume optimizer, lr_scheduler from a checkpoint\n",
    "    if configs.resume_path is not None:\n",
    "        utils_path = configs.resume_path.replace('Model_', 'Utils_')\n",
    "        assert os.path.isfile(utils_path), \"=> no checkpoint found at '{}'\".format(utils_path)\n",
    "        utils_state_dict = torch.load(utils_path, map_location='cuda:{}'.format(configs.gpu_idx))\n",
    "        optimizer.load_state_dict(utils_state_dict['optimizer'])\n",
    "        lr_scheduler.load_state_dict(utils_state_dict['lr_scheduler'])\n",
    "        configs.start_epoch = utils_state_dict['epoch'] + 1\n",
    "\n",
    "    if configs.is_master_node:\n",
    "        num_parameters = get_num_parameters(model)\n",
    "        logger.info('number of trained parameters of the model: {}'.format(num_parameters))\n",
    "\n",
    "    if logger is not None:\n",
    "        logger.info(\">>> Loading dataset & getting dataloader...\")\n",
    "    # Create dataloader\n",
    "    train_dataloader, train_sampler = create_train_dataloader(configs)\n",
    "    if logger is not None:\n",
    "        logger.info('number of batches in training set: {}'.format(len(train_dataloader)))\n",
    "\n",
    "    if configs.evaluate:\n",
    "        val_dataloader = create_val_dataloader(configs)\n",
    "        val_loss = validate(val_dataloader, model, configs)\n",
    "        print('val_loss: {:.4e}'.format(val_loss))\n",
    "        return\n",
    "\n",
    "    for epoch in range(configs.start_epoch, configs.num_epochs + 1):\n",
    "        if logger is not None:\n",
    "            logger.info('{}'.format('*-' * 40))\n",
    "            logger.info('{} {}/{} {}'.format('=' * 35, epoch, configs.num_epochs, '=' * 35))\n",
    "            logger.info('{}'.format('*-' * 40))\n",
    "            logger.info('>>> Epoch: [{}/{}]'.format(epoch, configs.num_epochs))\n",
    "\n",
    "        if configs.distributed:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "        # train for one epoch\n",
    "        train_one_epoch(train_dataloader, model, optimizer, lr_scheduler, epoch, configs, logger, tb_writer)\n",
    "        if (not configs.no_val) and (epoch % configs.checkpoint_freq == 0):\n",
    "            val_dataloader = create_val_dataloader(configs)\n",
    "            print('number of batches in val_dataloader: {}'.format(len(val_dataloader)))\n",
    "            val_loss = validate(val_dataloader, model, configs)\n",
    "            print('val_loss: {:.4e}'.format(val_loss))\n",
    "            if tb_writer is not None:\n",
    "                tb_writer.add_scalar('Val_loss', val_loss, epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        if configs.is_master_node and ((epoch % configs.checkpoint_freq) == 0):\n",
    "            model_state_dict, utils_state_dict = get_saved_state(model, optimizer, lr_scheduler, epoch, configs)\n",
    "            save_checkpoint(configs.checkpoints_dir, configs.saved_fn, model_state_dict, utils_state_dict, epoch)\n",
    "\n",
    "        if not configs.step_lr_in_epoch:\n",
    "            lr_scheduler.step()\n",
    "            if tb_writer is not None:\n",
    "                tb_writer.add_scalar('LR', lr_scheduler.get_lr()[0], epoch)\n",
    "\n",
    "    if tb_writer is not None:\n",
    "        tb_writer.close()\n",
    "    if configs.distributed:\n",
    "        cleanup()\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "def train_one_epoch(train_dataloader, model, optimizer, lr_scheduler, epoch, configs, logger, tb_writer):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "\n",
    "    progress = ProgressMeter(len(train_dataloader), [batch_time, data_time, losses],\n",
    "                             prefix=\"Train - Epoch: [{}/{}]\".format(epoch, configs.num_epochs))\n",
    "\n",
    "    criterion = Compute_Loss(device=configs.device)\n",
    "    num_iters_per_epoch = len(train_dataloader)\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    for batch_idx, batch_data in enumerate(tqdm(train_dataloader)):\n",
    "        data_time.update(time.time() - start_time)\n",
    "        metadatas, imgs, targets = batch_data\n",
    "        batch_size = imgs.size(0)\n",
    "        global_step = num_iters_per_epoch * (epoch - 1) + batch_idx + 1\n",
    "        for k in targets.keys():\n",
    "            targets[k] = targets[k].to(configs.device, non_blocking=True)\n",
    "        imgs = imgs.to(configs.device, non_blocking=True).float()\n",
    "        outputs = model(imgs)\n",
    "        total_loss, loss_stats = criterion(outputs, targets)\n",
    "        # For torch.nn.DataParallel case\n",
    "        if (not configs.distributed) and (configs.gpu_idx is None):\n",
    "            total_loss = torch.mean(total_loss)\n",
    "\n",
    "        # compute gradient and perform backpropagation\n",
    "        total_loss.backward()\n",
    "        if global_step % configs.subdivisions == 0:\n",
    "            optimizer.step()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Adjust learning rate\n",
    "            if configs.step_lr_in_epoch:\n",
    "                lr_scheduler.step()\n",
    "                if tb_writer is not None:\n",
    "                    tb_writer.add_scalar('LR', lr_scheduler.get_lr()[0], global_step)\n",
    "\n",
    "        if configs.distributed:\n",
    "            reduced_loss = reduce_tensor(total_loss.data, configs.world_size)\n",
    "        else:\n",
    "            reduced_loss = total_loss.data\n",
    "        losses.update(to_python_float(reduced_loss), batch_size)\n",
    "        # measure elapsed time\n",
    "        # torch.cuda.synchronize()\n",
    "        batch_time.update(time.time() - start_time)\n",
    "\n",
    "        if tb_writer is not None:\n",
    "            if (global_step % configs.tensorboard_freq) == 0:\n",
    "                loss_stats['avg_loss'] = losses.avg\n",
    "                tb_writer.add_scalars('Train', loss_stats, global_step)\n",
    "        # Log message\n",
    "        if logger is not None:\n",
    "            if (global_step % configs.print_freq) == 0:\n",
    "                logger.info(progress.get_message(batch_idx))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "def validate(val_dataloader, model, configs):\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    criterion = Compute_Loss(device=configs.device)\n",
    "    # switch to train mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(tqdm(val_dataloader)):\n",
    "            metadatas, imgs, targets = batch_data\n",
    "            batch_size = imgs.size(0)\n",
    "            for k in targets.keys():\n",
    "                targets[k] = targets[k].to(configs.device, non_blocking=True)\n",
    "            imgs = imgs.to(configs.device, non_blocking=True).float()\n",
    "            outputs = model(imgs)\n",
    "            total_loss, loss_stats = criterion(outputs, targets)\n",
    "            # For torch.nn.DataParallel case\n",
    "            if (not configs.distributed) and (configs.gpu_idx is None):\n",
    "                total_loss = torch.mean(total_loss)\n",
    "\n",
    "            if configs.distributed:\n",
    "                reduced_loss = reduce_tensor(total_loss.data, configs.world_size)\n",
    "            else:\n",
    "                reduced_loss = total_loss.data\n",
    "            losses.update(to_python_float(reduced_loss), batch_size)\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fea96ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:47.172184Z",
     "iopub.status.busy": "2024-05-05T12:49:47.171539Z",
     "iopub.status.idle": "2024-05-05T12:49:47.174187Z",
     "shell.execute_reply": "2024-05-05T12:49:47.173684Z",
     "shell.execute_reply.started": "2021-12-13T06:45:05.351101Z"
    },
    "papermill": {
     "duration": 0.053767,
     "end_time": "2024-05-05T12:49:47.174318",
     "exception": false,
     "start_time": "2024-05-05T12:49:47.120551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to start training\n",
    "# main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79457d13",
   "metadata": {
    "papermill": {
     "duration": 0.046863,
     "end_time": "2024-05-05T12:49:47.268621",
     "exception": false,
     "start_time": "2024-05-05T12:49:47.221758",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Demo Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88ee3701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:47.376491Z",
     "iopub.status.busy": "2024-05-05T12:49:47.371152Z",
     "iopub.status.idle": "2024-05-05T12:49:50.761155Z",
     "shell.execute_reply": "2024-05-05T12:49:50.760399Z",
     "shell.execute_reply.started": "2021-12-13T06:45:05.369109Z"
    },
    "papermill": {
     "duration": 3.44485,
     "end_time": "2024-05-05T12:49:50.761305",
     "exception": false,
     "start_time": "2024-05-05T12:49:47.316455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-05 12:49:49--  https://github.com/maudzung/SFA3D/raw/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth\r\n",
      "Resolving github.com (github.com)... 140.82.116.3\r\n",
      "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/maudzung/SFA3D/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth [following]\r\n",
      "--2024-05-05 12:49:49--  https://raw.githubusercontent.com/maudzung/SFA3D/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 50984463 (49M) [application/octet-stream]\r\n",
      "Saving to: ./checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth\r\n",
      "\r\n",
      "fpn_resnet_18_epoch 100%[===================>]  48.62M   245MB/s    in 0.2s    \r\n",
      "\r\n",
      "2024-05-05 12:49:50 (245 MB/s) - ./checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth saved [50984463/50984463]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Download weights\n",
    "!mkdir -p ./checkpoints/fpn_resnet_18\n",
    "!wget https://github.com/maudzung/SFA3D/raw/master/checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth -P ./checkpoints/fpn_resnet_18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f676fa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T12:49:50.888871Z",
     "iopub.status.busy": "2024-05-05T12:49:50.884613Z",
     "iopub.status.idle": "2024-05-05T12:51:41.685680Z",
     "shell.execute_reply": "2024-05-05T12:51:41.686209Z",
     "shell.execute_reply.started": "2021-12-13T06:45:07.741368Z"
    },
    "papermill": {
     "duration": 110.87309,
     "end_time": "2024-05-05T12:51:41.686392",
     "exception": false,
     "start_time": "2024-05-05T12:49:50.813302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading data for demonstration...\n",
      "\n",
      "Unzipping the downloaded data...\n",
      "using ResNet architecture with feature pyramid\n",
      "\n",
      "\n",
      "-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=-*=\n",
      "\n",
      "\n",
      "Loaded weights from ./checkpoints/fpn_resnet_18/fpn_resnet_18_epoch_300.pth\n",
      "\n",
      "Create video writer at ./results/fpn_resnet_18/2011_09_26_drive_0014_sync_both_2_sides.avi\n",
      "Video Created!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "configs = parse_demo_configs()\n",
    "\n",
    "# Try to download the dataset for demonstration\n",
    "server_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data'\n",
    "download_url = '{}/{}/{}.zip'.format(server_url, configs.foldername[:-5], configs.foldername)\n",
    "download_and_unzip(configs.dataset_dir, download_url)\n",
    "\n",
    "model = create_model(configs)\n",
    "print('\\n\\n' + '-*=' * 30 + '\\n\\n')\n",
    "assert os.path.isfile(configs.pretrained_path), \"No file at {}\".format(configs.pretrained_path)\n",
    "model.load_state_dict(torch.load(configs.pretrained_path, map_location='cpu'))\n",
    "print('Loaded weights from {}\\n'.format(configs.pretrained_path))\n",
    "\n",
    "configs.device = torch.device('cpu' if configs.no_cuda else 'cuda:{}'.format(configs.gpu_idx))\n",
    "model = model.to(device=configs.device)\n",
    "model.eval()\n",
    "\n",
    "out_cap = None\n",
    "demo_dataset = Demo_KittiDataset(configs)\n",
    "with torch.no_grad():\n",
    "    for sample_idx in range(len(demo_dataset)):\n",
    "        metadatas, front_bevmap, back_bevmap, img_rgb = demo_dataset.load_bevmap_front_vs_back(sample_idx)\n",
    "        front_detections, front_bevmap, fps = do_detect(configs, model, front_bevmap, is_front=True)\n",
    "        back_detections, back_bevmap, _ = do_detect(configs, model, back_bevmap, is_front=False)\n",
    "\n",
    "        # Draw prediction in the image\n",
    "        front_bevmap = (front_bevmap.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "        front_bevmap = cv2.resize(front_bevmap, (BEV_WIDTH, BEV_HEIGHT))\n",
    "        front_bevmap = draw_predictions(front_bevmap, front_detections, configs.num_classes)\n",
    "        # Rotate the front_bevmap\n",
    "        front_bevmap = cv2.rotate(front_bevmap, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        # Draw prediction in the image\n",
    "        back_bevmap = (back_bevmap.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "        back_bevmap = cv2.resize(back_bevmap, (BEV_WIDTH, BEV_HEIGHT))\n",
    "        back_bevmap = draw_predictions(back_bevmap, back_detections, configs.num_classes)\n",
    "        # Rotate the back_bevmap\n",
    "        back_bevmap = cv2.rotate(back_bevmap, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "        # merge front and back bevmap\n",
    "        full_bev = np.concatenate((back_bevmap, front_bevmap), axis=1)\n",
    "\n",
    "        img_path = metadatas['img_path'][0]\n",
    "        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "        calib = Calibration(configs.calib_path)\n",
    "        kitti_dets = convert_det_to_real_values(front_detections)\n",
    "        if len(kitti_dets) > 0:\n",
    "            kitti_dets[:, 1:] = lidar_to_camera_box(kitti_dets[:, 1:], calib.V2C, calib.R0, calib.P2)\n",
    "            img_bgr = show_rgb_image_with_boxes(img_bgr, kitti_dets, calib)\n",
    "        img_bgr = cv2.resize(img_bgr, (BEV_WIDTH * 2, 375))\n",
    "\n",
    "        out_img = np.concatenate((img_bgr, full_bev), axis=0)\n",
    "        write_credit(out_img, (50, 410), text_author='VK EXPLORATION', org_fps=(900, 410), fps=fps)\n",
    "\n",
    "        if out_cap is None:\n",
    "            out_cap_h, out_cap_w = out_img.shape[:2]\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "            out_path = os.path.join(configs.results_dir, '{}_both_2_sides.avi'.format(configs.foldername))\n",
    "            print('Create video writer at {}'.format(out_path))\n",
    "            out_cap = cv2.VideoWriter(out_path, fourcc, 5, (out_cap_w, out_cap_h))\n",
    "\n",
    "        out_cap.write(out_img)\n",
    "\n",
    "if out_cap:\n",
    "    out_cap.release()\n",
    "    \n",
    "print(\"Video Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2803075",
   "metadata": {
    "papermill": {
     "duration": 0.05036,
     "end_time": "2024-05-05T12:51:41.789484",
     "exception": false,
     "start_time": "2024-05-05T12:51:41.739124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1357458,
     "sourceId": 2255937,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30146,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 151.222952,
   "end_time": "2024-05-05T12:51:43.252755",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T12:49:12.029803",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
